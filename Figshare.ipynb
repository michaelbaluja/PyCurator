{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figshare API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilizes the Figshare API. Follow these steps in order to get the necessary credentials to continue:\n",
    "1. Create a Figshare account at https://figshare.com/account/register\n",
    "2. After logging in, click on your account photo in the top right corner, and then click on 'Applications'\n",
    "3. Access API key either by:\n",
    "    - Create an application by clicking on 'Create Application'\n",
    "    - Create an API key by clicking on 'Create Personal Token'\n",
    "4. Load API key:\n",
    "    - For repeated use, follow the ```pickle_tutorial.ipynb``` instructions to create create a ```./credentials.pkl``` file that holds a dictionary containing the entry ```{'FIGSHARE_TOKEN': MYKEY}```, with MYKEY being your API key.\n",
    "    - For sparser use, users can run the credentials cell and paste their API key when prompted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation Guide:\n",
    "- Figshare API ([Figshare](https://docs.figshare.com))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries\n",
    "\n",
    "#### Load API credentials\n",
    "\n",
    "#### Query #1: query API query based on search terms and search types\n",
    "\n",
    "Define functions to query API based on search terms and search types:\n",
    "\n",
    "1.\tFunction `get_individual_search_output` queries the Figshare API with the specified search term (e.g., “machine learning”) and search type (i.e., articles, collections, projects)\n",
    "    - Figshare allows a variety of search types. For this script, we search: (1) articles, (2) collections, and (3) projects.\n",
    "        - \"Articles\" in this context include a variety of item types: 1 - Figure, 2 - Media, 3 - Dataset, 5 - Poster, 6 - Journal contribution, 7 - Presentation, 8 - Thesis, 9 - Software, 11 - Online resource, 12 - Preprint, 13 - Book, 14 - Conference contribution, 15 - Chapter, 16 - Peer review, 17 - Educational resource, 18 - Report, 19 - Standard, 20 - Composition, 21 - Funding, 22 - Physical object, 23 - Data management plan, 24 - Workflow, 25 - Monograph, 26 - Performance, 27 - Event, 28 - Service, 29 - Model\n",
    "    - Searches across all returned pages\n",
    "    - Result is a dataframe (one dataframe per search term/search type combination)\n",
    "    - Each dataframe contains high level information about each object (i.e., id, title, doi, URL, etc)\n",
    "\n",
    "\n",
    "3.\tFunction `get_all_search_outputs` queries the Figshare API for all combinations of search terms and search types specified and returns the results as a dictionary of dataframes (one dataframe for each query combination)\n",
    "    - Calls function `get_individual_search_output` for each combination of search term and search type\n",
    "\n",
    "Run `get_all_search_outputs` for specified search terms and search types. Output is ordered dictionary of dataframes (result #1 \"ordered_dict\").\n",
    "\n",
    "#### Query #2: query API for full metadata for hits from initial query\n",
    "\n",
    "Following query #1 (resuling in result #1 \"ordered_dict\"), define functions to retrieve full metadata associated with each object.\n",
    "\n",
    "4.\tFunction `_retrieve_object_json` uses the URL for each object (from dataframe in result #1 \"ordered_dict\") to query API for metadata associated with each object. \n",
    "    - Returns flattened JSON object   \n",
    "    \n",
    "    \n",
    "5.\tFunction `get_metadata` extracts metadata associated with each object and formats as dataframe\n",
    "    - Calls function `_retrieve_object_json` to get full metadata for each object\n",
    "    - Output is single dataframe for each search query (matching each dataframe in result #1 \"ordered_dict\")\n",
    "    \n",
    "\n",
    "6. Use a `for` loop to put dataframes into an ordered dictionary, matching result #1 \"ordered_dict\" object\n",
    "    - Calls function `get_metadata`\n",
    "\n",
    "\n",
    "Run `for` loop (which calls `get_metadata`) to pull metadata for each object returned by query #1. Output is ordered dictionary of dataframes (result #2 \"metadata_dict\").\n",
    "\n",
    "We now have a dictionary of results from query #1 (object \"ordered_dict\", which includes high level metadata such as ID and title) and a dictionary of results with additional metadata for each object (object \"metadata_dict\").\n",
    "\n",
    "#### Merge results\n",
    "7.\tFunction `merge_search_and_metadata_dicts` merges these two dictionaries (\"ordered_dict\" and \"metadata_dict\") to a single ordered dictionary and (optional) saves the results as a single csv file\n",
    "\n",
    "Run merge function to access full ordered dictionary and optionally save results to csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # For querying data from API\n",
    "import pandas as pd # For storing/manipulating query data\n",
    "from tqdm import tqdm # Gives status bar on loop completion\n",
    "import itertools # For efficient looping over queries\n",
    "from collections import OrderedDict\n",
    "from flatten_json import flatten\n",
    "\n",
    "# For loading credentials\n",
    "import pickle\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API access tokens have been stored in credentials.pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "\n",
    "# Check for credentials file\n",
    "try:\n",
    "    with open('credentials.pkl', 'rb') as credentials:\n",
    "        FIGSHARE_TOKEN = pickle.load(credentials)['FIGSHARE_TOKEN']\n",
    "except:\n",
    "    FIGSHARE_TOKEN = input('Please enter your Figshare API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search constants\n",
    "BASE_URL = 'https://api.figshare.com/v2/'\n",
    "HEADERS = {'Authorization': f'token {FIGSHARE_TOKEN}'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query #1: query API based on search terms and search types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_search_outputs(search_terms, search_types, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Call the Figshare API for each search term and search type. \n",
    "    Results are retured in results['{term}_{type}'] = df\n",
    "    \n",
    "    Params:\n",
    "    - search_terms (list-like): collection of search terms to query over\n",
    "    - search_types (list-like): collection of search types to query over\n",
    "    - flatten_output (bool): optional, (default=False)\n",
    "    \n",
    "    Returns:\n",
    "    - results (dict): dictionary consisting of returned DataFrames from get_search_output for each query\n",
    "    \"\"\"\n",
    "    \n",
    "    num_searches = len(search_terms) * len(search_types)\n",
    "    results = OrderedDict()\n",
    "\n",
    "    for search_term, search_type in itertools.product(search_terms, search_types):\n",
    "        results[(search_term, search_type)] = get_individual_search_output(search_term, search_type, flatten_output)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_search_output(search_term, search_type, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Calls the Figshare API with the specified search term and returns the search output results.\n",
    "    \n",
    "    Params:\n",
    "    - search_term (str): keyword to seach for\n",
    "    - search_type (str): objects to search over (must be either datasets or kernels)\n",
    "    - flatten_output (bool): optional (default=False)\n",
    "   \n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): DataFrame containing the output of the search query\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make sure our input is valid\n",
    "    assert isinstance(search_term, str), 'Search term must be a string'\n",
    "    assert search_type in ('articles', 'collections', 'projects'), \\\n",
    "        'Search can only be conducted over articles, collections, or projects'\n",
    "        \n",
    "    # Set search variables\n",
    "    start_page = 1\n",
    "    page_size = 1000 # Maximum page size (min = 10)\n",
    "    output = None\n",
    "    search_df = pd.DataFrame()\n",
    "    \n",
    "    search_params = {\n",
    "        'search_for': search_term,\n",
    "        'page': start_page, \n",
    "        'page_size': page_size,  \n",
    "        }\n",
    "        \n",
    "    search_url = f'{BASE_URL}/{search_type}'\n",
    "\n",
    "    ## Run search for public articles\n",
    "    response = requests.get(search_url, params=search_params, headers=HEADERS)\n",
    "\n",
    "    ## Put output into json format\n",
    "    output = response.json()\n",
    "    \n",
    "    # Continue searching until we reach an empty page\n",
    "    while output != []:\n",
    "        # Flatten output if needed\n",
    "        if flatten_output:\n",
    "            output = [flatten(result) for result in output]\n",
    "        \n",
    "        # Turn outputs into DataFrame & add page info\n",
    "        output_df = pd.DataFrame(output)\n",
    "        output_df['search_page'] = search_params['page']\n",
    "        \n",
    "        # Append modified output df to our cumulative search DataFrame\n",
    "        search_df = pd.concat([search_df, output_df])\n",
    "        \n",
    "        # Increment page number to query\n",
    "        search_params['page'] += 1\n",
    "\n",
    "        ## Run search for public articles\n",
    "        response = requests.get(search_url, params=search_params, headers=HEADERS)\n",
    "\n",
    "        ## Put output into json format\n",
    "        output = response.json()\n",
    "    \n",
    "    return search_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run query #1 functions - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['iguana']\n",
    "search_types = ['collections', 'projects', 'articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_output_dict = get_all_search_outputs(search_terms, search_types, flatten_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key = (search_terms[0], search_types[0])\n",
    "sample_df = search_output_dict[sample_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>handle</th>\n",
       "      <th>url</th>\n",
       "      <th>published_date</th>\n",
       "      <th>timeline_posted</th>\n",
       "      <th>search_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3582815</td>\n",
       "      <td>Data from: Vascular patterns in iguanas and ot...</td>\n",
       "      <td>10.5061/dryad.27m63.2</td>\n",
       "      <td></td>\n",
       "      <td>https://api.figshare.com/v2/collections/3582815</td>\n",
       "      <td>2016-11-25T19:47:11Z</td>\n",
       "      <td>2016-11-25T19:47:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4755440</td>\n",
       "      <td>Data from: Vascular patterns in iguanas and ot...</td>\n",
       "      <td>10.5061/dryad.27m63</td>\n",
       "      <td></td>\n",
       "      <td>https://api.figshare.com/v2/collections/4755440</td>\n",
       "      <td>2019-11-26T08:07:43Z</td>\n",
       "      <td>2019-11-26T08:07:43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4596320</td>\n",
       "      <td>Data from: Vascular patterns in iguanas and ot...</td>\n",
       "      <td>10.5061/dryad.27m63.1</td>\n",
       "      <td></td>\n",
       "      <td>https://api.figshare.com/v2/collections/4596320</td>\n",
       "      <td>2019-07-30T16:44:02Z</td>\n",
       "      <td>2019-07-30T16:44:02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5234804</td>\n",
       "      <td>First known trace fossil of a nesting iguana (...</td>\n",
       "      <td>10.1371/journal.pone.0242935</td>\n",
       "      <td></td>\n",
       "      <td>https://api.figshare.com/v2/collections/5234804</td>\n",
       "      <td>2020-12-09T18:32:22Z</td>\n",
       "      <td>2020-12-09T18:32:22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5311858</td>\n",
       "      <td>Systemic &lt;i&gt;Helicobacter&lt;/i&gt; infection and ass...</td>\n",
       "      <td>10.1371/journal.pone.0247010</td>\n",
       "      <td></td>\n",
       "      <td>https://api.figshare.com/v2/collections/5311858</td>\n",
       "      <td>2021-02-19T18:33:04Z</td>\n",
       "      <td>2021-02-19T18:33:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  3582815  Data from: Vascular patterns in iguanas and ot...   \n",
       "1  4755440  Data from: Vascular patterns in iguanas and ot...   \n",
       "2  4596320  Data from: Vascular patterns in iguanas and ot...   \n",
       "3  5234804  First known trace fossil of a nesting iguana (...   \n",
       "4  5311858  Systemic <i>Helicobacter</i> infection and ass...   \n",
       "\n",
       "                            doi handle  \\\n",
       "0         10.5061/dryad.27m63.2          \n",
       "1           10.5061/dryad.27m63          \n",
       "2         10.5061/dryad.27m63.1          \n",
       "3  10.1371/journal.pone.0242935          \n",
       "4  10.1371/journal.pone.0247010          \n",
       "\n",
       "                                               url        published_date  \\\n",
       "0  https://api.figshare.com/v2/collections/3582815  2016-11-25T19:47:11Z   \n",
       "1  https://api.figshare.com/v2/collections/4755440  2019-11-26T08:07:43Z   \n",
       "2  https://api.figshare.com/v2/collections/4596320  2019-07-30T16:44:02Z   \n",
       "3  https://api.figshare.com/v2/collections/5234804  2020-12-09T18:32:22Z   \n",
       "4  https://api.figshare.com/v2/collections/5311858  2021-02-19T18:33:04Z   \n",
       "\n",
       "       timeline_posted  search_page  \n",
       "0  2016-11-25T19:47:11            1  \n",
       "1  2019-11-26T08:07:43            1  \n",
       "2  2019-07-30T16:44:02            1  \n",
       "3  2020-12-09T18:32:22            1  \n",
       "4  2021-02-19T18:33:04            1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query #2: query API for full metadata for hits from query #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _retrieve_object_json(object_url, flatten_output=False):\n",
    "    '''\n",
    "    Queries Figshare for object data (json file) & returns the json data as a dictionary\n",
    "    \n",
    "    Params:\n",
    "    - object_url (str): path for the dataset\n",
    "    - flatten_output (bool): optional (default=False)\n",
    "    \n",
    "    Returns:\n",
    "    - object_data_dict (dict): dictionary containing json data\n",
    "    '''\n",
    "    \n",
    "    # Download the metadata\n",
    "    response = requests.get(object_url, headers=HEADERS)\n",
    "    json_data = response.json()\n",
    "    \n",
    "    # Flatten json\n",
    "    if flatten_output:\n",
    "        json_data = flatten(json_data)\n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_metadata(object_paths, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Retrieves the metadata for the object/objects listed in object_paths\n",
    "    \n",
    "    Params:\n",
    "    - object_paths (str/list-like): string or list of strings containing the paths for the objects\n",
    "    - flatten_output (bool): optional, (default=False)\n",
    "    \n",
    "    Returns:\n",
    "    - metadata_df (pandas.DataFrame): DataFrame containing metadata for the requested objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # If a singular search term is provided as a string, need to wrap it in a list\n",
    "    if type(object_paths) == str:\n",
    "        object_paths = [object_paths]\n",
    "    \n",
    "    # Make sure our input is valid\n",
    "    assert len(object_paths) > 0, 'Please enter at least one object id'\n",
    "    \n",
    "    #create empty pandas dataframe to put results in\n",
    "    metadata_df = pd.DataFrame()\n",
    "\n",
    "    #for each path, get full object details\n",
    "    for object_path in tqdm(object_paths):\n",
    "        #URL syntax for object details is: https://api.figshare.com/v2/{search_type}/{object_id}        \n",
    "        json_data = _retrieve_object_json(object_path, flatten_output)\n",
    "        \n",
    "        #appending json collapses first level, which is a start\n",
    "        #for now, can leave files, custom fields, author, etc as list of dictionary\n",
    "        metadata_df = metadata_df.append(json_data, ignore_index=True)\n",
    "        \n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run query #2  functions - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metadata(search_output_dict, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Retrieves all of the metadata that relates to the provided DataFrames\n",
    "    \n",
    "    Params:\n",
    "    - search_output_dict : dict\n",
    "        Dictionary of DataFrames from get_all_search_outputs\n",
    "    - flatten_output : bool, optional (default=False)\n",
    "        flag for flattening nested columns of output  \n",
    "      \n",
    "    Returns:\n",
    "    - metadata_dict : collections.OrderedDict\n",
    "        OrderedDict of DataFrames with metadata for each query\n",
    "        Order matches the order of search_output_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Extract IDs from DataFrame, and returns as list of strings\n",
    "    metadata_dict = OrderedDict()\n",
    "\n",
    "    for query, df in search_output_dict.items():\n",
    "        print(f'Retrieving {query} metadata')\n",
    "        # Create object paths\n",
    "        _, search_type = query\n",
    "        object_ids = df.id.convert_dtypes(convert_string=True).tolist()\n",
    "        object_paths = [f'{BASE_URL}/{search_type}/{object_id}' for object_id in object_ids]\n",
    "\n",
    "        metadata_dict[query] = get_query_metadata(object_paths, flatten_output)\n",
    "    \n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving ('iguana', 'collections') metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:40<00:00,  1.02it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving ('iguana', 'projects') metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.04it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving ('iguana', 'articles') metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [02:50<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "metadata_dict = get_all_metadata(search_output_dict, flatten_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_0_full_name</th>\n",
       "      <th>authors_0_id</th>\n",
       "      <th>authors_0_is_active</th>\n",
       "      <th>authors_0_orcid_id</th>\n",
       "      <th>authors_0_url_name</th>\n",
       "      <th>authors_1_full_name</th>\n",
       "      <th>authors_1_id</th>\n",
       "      <th>authors_1_is_active</th>\n",
       "      <th>authors_1_orcid_id</th>\n",
       "      <th>authors_1_url_name</th>\n",
       "      <th>...</th>\n",
       "      <th>categories_12_parent_id</th>\n",
       "      <th>categories_12_title</th>\n",
       "      <th>categories_13_id</th>\n",
       "      <th>categories_13_parent_id</th>\n",
       "      <th>categories_13_title</th>\n",
       "      <th>tags_27</th>\n",
       "      <th>tags_28</th>\n",
       "      <th>tags_29</th>\n",
       "      <th>tags_30</th>\n",
       "      <th>tags_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Ruger Porter</td>\n",
       "      <td>813288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Lawrence M. Witmer</td>\n",
       "      <td>36585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>Lawrence_M_Witmer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William Ruger Porter</td>\n",
       "      <td>813288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Lawrence M. Witmer</td>\n",
       "      <td>36585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>Lawrence_M_Witmer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Ruger Porter</td>\n",
       "      <td>813288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Lawrence M. Witmer</td>\n",
       "      <td>36585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>Lawrence_M_Witmer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>William Ruger Porter</td>\n",
       "      <td>813288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Lawrence M. Witmer</td>\n",
       "      <td>36585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>Lawrence_M_Witmer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William Ruger Porter</td>\n",
       "      <td>813288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Lawrence M. Witmer</td>\n",
       "      <td>36585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>Lawrence_M_Witmer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Stephanie Guyomard-Rabenirina</td>\n",
       "      <td>9108587.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Yann Reynaud</td>\n",
       "      <td>503432.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Stephanie Guyomard-Rabenirina</td>\n",
       "      <td>9108587.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Yann Reynaud</td>\n",
       "      <td>503432.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Stephanie Guyomard-Rabenirina</td>\n",
       "      <td>9108587.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Yann Reynaud</td>\n",
       "      <td>503432.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Audrey Jean</td>\n",
       "      <td>3772594.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Florence Tardy</td>\n",
       "      <td>433541.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Plant Biology</td>\n",
       "      <td>134.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Virology</td>\n",
       "      <td>U 1</td>\n",
       "      <td>16 S rDNA copies</td>\n",
       "      <td>16 S rDNA</td>\n",
       "      <td>Mollicute class</td>\n",
       "      <td>reference DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Kaleb Pretto Gatto</td>\n",
       "      <td>2805271.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Carmen Silvia Busin</td>\n",
       "      <td>2805277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 664 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               authors_0_full_name  authors_0_id  authors_0_is_active  \\\n",
       "0             William Ruger Porter      813288.0                  0.0   \n",
       "1             William Ruger Porter      813288.0                  0.0   \n",
       "2             William Ruger Porter      813288.0                  0.0   \n",
       "3             William Ruger Porter      813288.0                  0.0   \n",
       "4             William Ruger Porter      813288.0                  0.0   \n",
       "..                             ...           ...                  ...   \n",
       "147  Stephanie Guyomard-Rabenirina     9108587.0                  0.0   \n",
       "148  Stephanie Guyomard-Rabenirina     9108587.0                  0.0   \n",
       "149  Stephanie Guyomard-Rabenirina     9108587.0                  0.0   \n",
       "150                    Audrey Jean     3772594.0                  0.0   \n",
       "151             Kaleb Pretto Gatto     2805271.0                  0.0   \n",
       "\n",
       "    authors_0_orcid_id authors_0_url_name  authors_1_full_name  authors_1_id  \\\n",
       "0                                       _   Lawrence M. Witmer       36585.0   \n",
       "1                                       _   Lawrence M. Witmer       36585.0   \n",
       "2                                       _   Lawrence M. Witmer       36585.0   \n",
       "3                                       _   Lawrence M. Witmer       36585.0   \n",
       "4                                       _   Lawrence M. Witmer       36585.0   \n",
       "..                 ...                ...                  ...           ...   \n",
       "147                                     _         Yann Reynaud      503432.0   \n",
       "148                                     _         Yann Reynaud      503432.0   \n",
       "149                                     _         Yann Reynaud      503432.0   \n",
       "150                                     _       Florence Tardy      433541.0   \n",
       "151                                     _  Carmen Silvia Busin     2805277.0   \n",
       "\n",
       "     authors_1_is_active authors_1_orcid_id authors_1_url_name  ...  \\\n",
       "0                    0.0                     Lawrence_M_Witmer  ...   \n",
       "1                    0.0                     Lawrence_M_Witmer  ...   \n",
       "2                    0.0                     Lawrence_M_Witmer  ...   \n",
       "3                    0.0                     Lawrence_M_Witmer  ...   \n",
       "4                    0.0                     Lawrence_M_Witmer  ...   \n",
       "..                   ...                ...                ...  ...   \n",
       "147                  0.0                                     _  ...   \n",
       "148                  0.0                                     _  ...   \n",
       "149                  0.0                                     _  ...   \n",
       "150                  0.0                                     _  ...   \n",
       "151                  0.0                                     _  ...   \n",
       "\n",
       "     categories_12_parent_id  categories_12_title categories_13_id  \\\n",
       "0                        NaN                  NaN              NaN   \n",
       "1                        NaN                  NaN              NaN   \n",
       "2                        NaN                  NaN              NaN   \n",
       "3                        NaN                  NaN              NaN   \n",
       "4                        NaN                  NaN              NaN   \n",
       "..                       ...                  ...              ...   \n",
       "147                      NaN                  NaN              NaN   \n",
       "148                      NaN                  NaN              NaN   \n",
       "149                      NaN                  NaN              NaN   \n",
       "150                     48.0        Plant Biology            134.0   \n",
       "151                      NaN                  NaN              NaN   \n",
       "\n",
       "     categories_13_parent_id  categories_13_title tags_27           tags_28  \\\n",
       "0                        NaN                  NaN     NaN               NaN   \n",
       "1                        NaN                  NaN     NaN               NaN   \n",
       "2                        NaN                  NaN     NaN               NaN   \n",
       "3                        NaN                  NaN     NaN               NaN   \n",
       "4                        NaN                  NaN     NaN               NaN   \n",
       "..                       ...                  ...     ...               ...   \n",
       "147                      NaN                  NaN     NaN               NaN   \n",
       "148                      NaN                  NaN     NaN               NaN   \n",
       "149                      NaN                  NaN     NaN               NaN   \n",
       "150                     48.0             Virology     U 1  16 S rDNA copies   \n",
       "151                      NaN                  NaN     NaN               NaN   \n",
       "\n",
       "       tags_29          tags_30        tags_31  \n",
       "0          NaN              NaN            NaN  \n",
       "1          NaN              NaN            NaN  \n",
       "2          NaN              NaN            NaN  \n",
       "3          NaN              NaN            NaN  \n",
       "4          NaN              NaN            NaN  \n",
       "..         ...              ...            ...  \n",
       "147        NaN              NaN            NaN  \n",
       "148        NaN              NaN            NaN  \n",
       "149        NaN              NaN            NaN  \n",
       "150  16 S rDNA  Mollicute class  reference DNA  \n",
       "151        NaN              NaN            NaN  \n",
       "\n",
       "[152 rows x 664 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_dict[('iguana', 'articles')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge results of query #1 and query #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_search_and_metadata_dicts(search_dict, metadata_dict, on=None, left_on=None, right_on=None, save=False):\n",
    "    \"\"\"\n",
    "    Merges together all of the search and metadata DataFrames by the given 'on' key\n",
    "    \n",
    "    Params:\n",
    "    - search_dict (dict): dictionary of search output results\n",
    "    - metadata_dict (dict): dictionary of metadata results\n",
    "    - on (str/list-like): column name(s) to merge the two dicts on\n",
    "    - left_on (str/list-like): column name(s) to merge the left dict on\n",
    "    - right_on (str/list-like): column name(s) to merge the right dict on\n",
    "    - save=False, optional (bool/list-like): specifies if the output DataFrames should be saved\n",
    "        If True: saves to file of format 'data/kaggle/kaggle_{search_term}_{search_type}.csv'\n",
    "        If list-like: saves to respective location in list of save locations\n",
    "            Must contain enough strings (one per query; len(search_terms) * len(search_types))\n",
    "            \n",
    "    Returns:\n",
    "    - df_dict (OrderedDict): OrderedDict containing all of the merged search/metadata dicts\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure the dictionaries contain the same searches\n",
    "    assert search_dict.keys() == metadata_dict.keys(), 'Dictionaries must contain the same searches'\n",
    "    \n",
    "    num_dataframes = len(search_dict)\n",
    "    \n",
    "    # Ensure the save variable data is proper\n",
    "    try:\n",
    "        if isinstance(save, bool):\n",
    "            save = [save] * num_dataframes\n",
    "        assert len(save) == num_dataframes\n",
    "    except:\n",
    "        raise ValueError('Incorrect save value(s)')\n",
    "        \n",
    "    # Merge the DataFrames\n",
    "    df_dict = OrderedDict()\n",
    "    for (query_key, search_df), (query_key, metadata_df), save_loc in zip(search_dict.items(), \n",
    "                                                                          metadata_dict.items(), \n",
    "                                                                          save):\n",
    "        # Keep just search info, id and timeline from initial extract \n",
    "        # Timeline only present in some search types\n",
    "        columns_to_keep = ['id', 'search_page']\n",
    "        \n",
    "        if 'timeline' in search_df.columns:\n",
    "            columns_to_keep.append('timeline')\n",
    "            \n",
    "        search_df = search_df[columns_to_keep]\n",
    "\n",
    "        # Merge small version of \"full\" dataframe with \"detailed\" dataframe\n",
    "        df_all = pd.merge(search_df, metadata_df, on=on, left_on=left_on, right_on=right_on, how='outer')\n",
    "            \n",
    "        # Save DataFrame\n",
    "        if save_loc:\n",
    "            data_dir = os.path.join('data', 'figshare')\n",
    "            if isinstance(save_loc, str):\n",
    "                output_file = save_loc\n",
    "            elif isinstance(save_loc, bool):\n",
    "                # Ensure figshare directory is already created\n",
    "                if not os.path.isdir(data_dir):\n",
    "                    os.path.mkdir(data_dir)\n",
    "                \n",
    "                search_term, search_type = query_key\n",
    "                output_file = f'{search_term}_{search_type}.csv'\n",
    "            else:\n",
    "                raise ValueError(f'Save type must be bool or str, not {type(save_loc)}')\n",
    "\n",
    "            search_df.to_csv(os.path.join(data_dir, output_file), index=False)\n",
    "        \n",
    "        df_dict[query_key] = df_all\n",
    "    \n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run merge function - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = merge_search_and_metadata_dicts(search_output_dict, metadata_dict, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results of query #1\n",
    "output_df = search_output_dict[('iguana', 'articles')]\n",
    "\n",
    "#results of query #2\n",
    "metadata_df = metadata_dict[('iguana', 'articles')]\n",
    "\n",
    "#result of merging datasets into \"full\" dataframe\n",
    "full_df = df_dict[('iguana', 'articles')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>search_page</th>\n",
       "      <th>authors_0_full_name</th>\n",
       "      <th>authors_0_id</th>\n",
       "      <th>authors_0_is_active</th>\n",
       "      <th>authors_0_orcid_id</th>\n",
       "      <th>authors_0_url_name</th>\n",
       "      <th>authors_1_full_name</th>\n",
       "      <th>authors_1_id</th>\n",
       "      <th>authors_1_is_active</th>\n",
       "      <th>...</th>\n",
       "      <th>categories_12_parent_id</th>\n",
       "      <th>categories_12_title</th>\n",
       "      <th>categories_13_id</th>\n",
       "      <th>categories_13_parent_id</th>\n",
       "      <th>categories_13_title</th>\n",
       "      <th>tags_27</th>\n",
       "      <th>tags_28</th>\n",
       "      <th>tags_29</th>\n",
       "      <th>tags_30</th>\n",
       "      <th>tags_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9172331</td>\n",
       "      <td>1</td>\n",
       "      <td>William Ruger Porter</td>\n",
       "      <td>813288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Lawrence M. Witmer</td>\n",
       "      <td>36585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9172307</td>\n",
       "      <td>1</td>\n",
       "      <td>William Ruger Porter</td>\n",
       "      <td>813288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Lawrence M. Witmer</td>\n",
       "      <td>36585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9172310</td>\n",
       "      <td>1</td>\n",
       "      <td>William Ruger Porter</td>\n",
       "      <td>813288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Lawrence M. Witmer</td>\n",
       "      <td>36585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9172322</td>\n",
       "      <td>1</td>\n",
       "      <td>William Ruger Porter</td>\n",
       "      <td>813288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Lawrence M. Witmer</td>\n",
       "      <td>36585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9172319</td>\n",
       "      <td>1</td>\n",
       "      <td>William Ruger Porter</td>\n",
       "      <td>813288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>Lawrence M. Witmer</td>\n",
       "      <td>36585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 665 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  search_page   authors_0_full_name  authors_0_id  \\\n",
       "0  9172331            1  William Ruger Porter      813288.0   \n",
       "1  9172307            1  William Ruger Porter      813288.0   \n",
       "2  9172310            1  William Ruger Porter      813288.0   \n",
       "3  9172322            1  William Ruger Porter      813288.0   \n",
       "4  9172319            1  William Ruger Porter      813288.0   \n",
       "\n",
       "   authors_0_is_active authors_0_orcid_id authors_0_url_name  \\\n",
       "0                  0.0                                     _   \n",
       "1                  0.0                                     _   \n",
       "2                  0.0                                     _   \n",
       "3                  0.0                                     _   \n",
       "4                  0.0                                     _   \n",
       "\n",
       "  authors_1_full_name  authors_1_id  authors_1_is_active  ...  \\\n",
       "0  Lawrence M. Witmer       36585.0                  0.0  ...   \n",
       "1  Lawrence M. Witmer       36585.0                  0.0  ...   \n",
       "2  Lawrence M. Witmer       36585.0                  0.0  ...   \n",
       "3  Lawrence M. Witmer       36585.0                  0.0  ...   \n",
       "4  Lawrence M. Witmer       36585.0                  0.0  ...   \n",
       "\n",
       "  categories_12_parent_id categories_12_title  categories_13_id  \\\n",
       "0                     NaN                 NaN               NaN   \n",
       "1                     NaN                 NaN               NaN   \n",
       "2                     NaN                 NaN               NaN   \n",
       "3                     NaN                 NaN               NaN   \n",
       "4                     NaN                 NaN               NaN   \n",
       "\n",
       "   categories_13_parent_id categories_13_title  tags_27  tags_28 tags_29  \\\n",
       "0                      NaN                 NaN      NaN      NaN     NaN   \n",
       "1                      NaN                 NaN      NaN      NaN     NaN   \n",
       "2                      NaN                 NaN      NaN      NaN     NaN   \n",
       "3                      NaN                 NaN      NaN      NaN     NaN   \n",
       "4                      NaN                 NaN      NaN      NaN     NaN   \n",
       "\n",
       "   tags_30  tags_31  \n",
       "0      NaN      NaN  \n",
       "1      NaN      NaN  \n",
       "2      NaN      NaN  \n",
       "3      NaN      NaN  \n",
       "4      NaN      NaN  \n",
       "\n",
       "[5 rows x 665 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
