{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d1f0e5",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677bdca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import openml, installing if necessary\n",
    "try:\n",
    "    import openml\n",
    "except ImportError as e:\n",
    "    !pip3 install openml\n",
    "    import openml\n",
    "\n",
    "import pandas as pd # For storing/manipulating query data\n",
    "import pickle # For loading credentials\n",
    "import os # For loading credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4552c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "\n",
    "# Check if config file or CLI variable already set key value\n",
    "try:\n",
    "    assert openml.config.apikey != ''\n",
    "except AssertionError:\n",
    "    # Check for credentials file\n",
    "    if os.path.exists('credentials.pkl'):\n",
    "        with open('credentials.pkl', 'rb') as credentials:\n",
    "            openml.config.apikey = pickle.load(credentials)['OPENML_TOKEN']\n",
    "    else:\n",
    "        openml.config.apikey = input('Please enter your OpenML API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c707fa",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ecd3a1",
   "metadata": {},
   "source": [
    "\\[1\\] https://www.w3schools.com/python/ref_func_vars.asp\n",
    "\n",
    "\\[2\\] https://www.geeksforgeeks.org/python-dir-function/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fbf96",
   "metadata": {},
   "source": [
    "# Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d80a89",
   "metadata": {},
   "source": [
    "Since the general work flow is identical for Datasets, Runs, and Tasks, we condense this explanation down to just showing an example for Datasets for the initial walkthrough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf637e",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e333b6",
   "metadata": {},
   "source": [
    "We first query OpenML for a couple of datasets using the list_datasets() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53bbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = openml.datasets.list_datasets(size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495bc61",
   "metadata": {},
   "source": [
    "The list_datasets function returns high level information about the datasets as an Ordered Dictionary. Each entry in the OrderedDict is a dictionary containing information for a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c4a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the OrderedDict keys in order to take a look at an example of the data returned.\n",
    "# Since the odict_keys object returned is not subscriptable, we cast it as a list and then take the first key\n",
    "dataset_list_keys = dataset_list.keys()\n",
    "sample_dataset_key = list(dataset_list_keys)[0]\n",
    "sample_dataset_info = dataset_list[sample_dataset_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7637a51f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'did': 2,\n",
       " 'name': 'anneal',\n",
       " 'version': 1,\n",
       " 'uploader': '1',\n",
       " 'status': 'active',\n",
       " 'format': 'ARFF',\n",
       " 'MajorityClassSize': 684.0,\n",
       " 'MaxNominalAttDistinctValues': 7.0,\n",
       " 'MinorityClassSize': 8.0,\n",
       " 'NumberOfClasses': 5.0,\n",
       " 'NumberOfFeatures': 39.0,\n",
       " 'NumberOfInstances': 898.0,\n",
       " 'NumberOfInstancesWithMissingValues': 898.0,\n",
       " 'NumberOfMissingValues': 22175.0,\n",
       " 'NumberOfNumericFeatures': 6.0,\n",
       " 'NumberOfSymbolicFeatures': 33.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53583ac",
   "metadata": {},
   "source": [
    "The 'did' entry contains the (d)ataset (id), which we then want to use in order to retrieve the dataset object via the get_dataset() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "949d7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract the dataset id from the samle dataset in order to search for it\n",
    "sample_id = sample_dataset_info['did']\n",
    "sample_dataset = openml.datasets.get_dataset(sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e76ce6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenML Dataset\n",
       "==============\n",
       "Name..........: anneal\n",
       "Version.......: 1\n",
       "Format........: ARFF\n",
       "Upload Date...: 2014-04-06 23:19:24\n",
       "Licence.......: Public\n",
       "Download URL..: https://www.openml.org/data/v1/download/1666876/anneal.arff\n",
       "OpenML URL....: https://www.openml.org/d/2\n",
       "# of features.: 39\n",
       "# of instances: 898"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c7ad47",
   "metadata": {},
   "source": [
    "Taking a look at the dataset, we see that there isn't really much information we can use from this. Most of the information is already present from the list_datasets() function. To get a better understanding of what these dataset objects contain, we can use the vars() function to see all of the object's changeable attributes \\[1\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ad6424",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_dataset_vars = vars(sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d4ac72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_id': 2,\n",
       " 'name': 'anneal',\n",
       " 'version': 1,\n",
       " 'description': \"**Author**: Unknown. Donated by David Sterling and Wray Buntine  \\n\\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Annealing) - 1990  \\n\\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  \\n\\n\\n\\nThe original Annealing dataset from UCI. The exact meaning of the features and classes is largely unknown. Annealing, in metallurgy and materials science, is a heat treatment that alters the physical and sometimes chemical properties of a material to increase its ductility and reduce its hardness, making it more workable. It involves heating a material to above its recrystallization temperature, maintaining a suitable temperature, and then cooling. (Wikipedia)\\n\\n\\n\\n### Attribute Information:\\n\\n     1. family:          --,GB,GK,GS,TN,ZA,ZF,ZH,ZM,ZS\\n\\n     2. product-type:    C, H, G\\n\\n     3. steel:           -,R,A,U,K,M,S,W,V\\n\\n     4. carbon:          continuous\\n\\n     5. hardness:        continuous\\n\\n     6. temper_rolling:  -,T\\n\\n     7. condition:       -,S,A,X\\n\\n     8. formability:     -,1,2,3,4,5\\n\\n     9. strength:        continuous\\n\\n    10. non-ageing:      -,N\\n\\n    11. surface-finish:  P,M,-\\n\\n    12. surface-quality: -,D,E,F,G\\n\\n    13. enamelability:   -,1,2,3,4,5\\n\\n    14. bc:              Y,-\\n\\n    15. bf:              Y,-\\n\\n    16. bt:              Y,-\\n\\n    17. bw/me:           B,M,-\\n\\n    18. bl:              Y,-\\n\\n    19. m:               Y,-\\n\\n    20. chrom:           C,-\\n\\n    21. phos:            P,-\\n\\n    22. cbond:           Y,-\\n\\n    23. marvi:           Y,-\\n\\n    24. exptl:           Y,-\\n\\n    25. ferro:           Y,-\\n\\n    26. corr:            Y,-\\n\\n    27. blue/bright/varn/clean:          B,R,V,C,-\\n\\n    28. lustre:          Y,-\\n\\n    29. jurofm:          Y,-\\n\\n    30. s:               Y,-\\n\\n    31. p:               Y,-\\n\\n    32. shape:           COIL, SHEET\\n\\n    33. thick:           continuous\\n\\n    34. width:           continuous\\n\\n    35. len:             continuous\\n\\n    36. oil:             -,Y,N\\n\\n    37. bore:            0000,0500,0600,0760\\n\\n    38. packing: -,1,2,3\\n\\n    classes:        1,2,3,4,5,U\\n\\n  \\n\\n    -- The '-' values are actually 'not_applicable' values rather than\\n\\n       'missing_values' (and so can be treated as legal discrete\\n\\n       values rather than as showing the absence of a discrete value).\",\n",
       " 'cache_format': 'pickle',\n",
       " 'format': 'ARFF',\n",
       " 'creator': ['David Sterling', 'Wray Buntine'],\n",
       " 'contributor': 'David Sterling and Wray Buntine',\n",
       " 'collection_date': '1990',\n",
       " 'upload_date': '2014-04-06T23:19:24',\n",
       " 'language': 'English',\n",
       " 'licence': 'Public',\n",
       " 'url': 'https://www.openml.org/data/v1/download/1666876/anneal.arff',\n",
       " 'default_target_attribute': 'class',\n",
       " 'row_id_attribute': None,\n",
       " 'ignore_attribute': None,\n",
       " 'version_label': '1',\n",
       " 'citation': 'https://archive.ics.uci.edu/ml/citation_policy.html',\n",
       " 'tag': ['study_1',\n",
       "  'study_14',\n",
       "  'study_34',\n",
       "  'study_37',\n",
       "  'study_41',\n",
       "  'study_70',\n",
       "  'study_76',\n",
       "  'test',\n",
       "  'uci'],\n",
       " 'visibility': 'public',\n",
       " 'original_data_url': 'https://archive.ics.uci.edu/ml/datasets/Annealing',\n",
       " 'paper_url': None,\n",
       " 'update_comment': None,\n",
       " 'md5_checksum': '4eaed8b6ec9d8211024b6c089b064761',\n",
       " 'data_file': '/Users/michaelbaluja/.openml/org/openml/www/datasets/2/dataset.arff',\n",
       " 'parquet_file': None,\n",
       " '_dataset': None,\n",
       " '_minio_url': 'http://openml1.win.tue.nl/dataset2/dataset_2.pq',\n",
       " 'features': {0: [0 - family (nominal)],\n",
       "  1: [1 - product-type (nominal)],\n",
       "  2: [2 - steel (nominal)],\n",
       "  3: [3 - carbon (numeric)],\n",
       "  4: [4 - hardness (numeric)],\n",
       "  5: [5 - temper_rolling (nominal)],\n",
       "  6: [6 - condition (nominal)],\n",
       "  7: [7 - formability (nominal)],\n",
       "  8: [8 - strength (numeric)],\n",
       "  9: [9 - non-ageing (nominal)],\n",
       "  10: [10 - surface-finish (nominal)],\n",
       "  11: [11 - surface-quality (nominal)],\n",
       "  12: [12 - enamelability (nominal)],\n",
       "  13: [13 - bc (nominal)],\n",
       "  14: [14 - bf (nominal)],\n",
       "  15: [15 - bt (nominal)],\n",
       "  16: [16 - bw%2Fme (nominal)],\n",
       "  17: [17 - bl (nominal)],\n",
       "  18: [18 - m (nominal)],\n",
       "  19: [19 - chrom (nominal)],\n",
       "  20: [20 - phos (nominal)],\n",
       "  21: [21 - cbond (nominal)],\n",
       "  22: [22 - marvi (nominal)],\n",
       "  23: [23 - exptl (nominal)],\n",
       "  24: [24 - ferro (nominal)],\n",
       "  25: [25 - corr (nominal)],\n",
       "  26: [26 - blue%2Fbright%2Fvarn%2Fclean (nominal)],\n",
       "  27: [27 - lustre (nominal)],\n",
       "  28: [28 - jurofm (nominal)],\n",
       "  29: [29 - s (nominal)],\n",
       "  30: [30 - p (nominal)],\n",
       "  31: [31 - shape (nominal)],\n",
       "  32: [32 - thick (numeric)],\n",
       "  33: [33 - width (numeric)],\n",
       "  34: [34 - len (numeric)],\n",
       "  35: [35 - oil (nominal)],\n",
       "  36: [36 - bore (nominal)],\n",
       "  37: [37 - packing (nominal)],\n",
       "  38: [38 - class (nominal)]},\n",
       " 'qualities': {'AutoCorrelation': 0.6064659977703456,\n",
       "  'CfsSubsetEval_DecisionStumpAUC': 0.9067742570970945,\n",
       "  'CfsSubsetEval_DecisionStumpErrRate': 0.13251670378619154,\n",
       "  'CfsSubsetEval_DecisionStumpKappa': 0.6191022730108037,\n",
       "  'CfsSubsetEval_NaiveBayesAUC': 0.9067742570970945,\n",
       "  'CfsSubsetEval_NaiveBayesErrRate': 0.13251670378619154,\n",
       "  'CfsSubsetEval_NaiveBayesKappa': 0.6191022730108037,\n",
       "  'CfsSubsetEval_kNN1NAUC': 0.9067742570970945,\n",
       "  'CfsSubsetEval_kNN1NErrRate': 0.13251670378619154,\n",
       "  'CfsSubsetEval_kNN1NKappa': 0.6191022730108037,\n",
       "  'ClassEntropy': 1.189833856204398,\n",
       "  'DecisionStumpAUC': 0.8652735384332186,\n",
       "  'DecisionStumpErrRate': 0.22828507795100222,\n",
       "  'DecisionStumpKappa': 0.4503332218612649,\n",
       "  'Dimensionality': 0.043429844097995544,\n",
       "  'EquivalentNumberOfAtts': 26.839183802676523,\n",
       "  'J48.00001.AUC': 0.9391585368767195,\n",
       "  'J48.00001.ErrRate': 0.10356347438752785,\n",
       "  'J48.00001.Kappa': 0.7043302166347443,\n",
       "  'J48.0001.AUC': 0.9391585368767195,\n",
       "  'J48.0001.ErrRate': 0.10356347438752785,\n",
       "  'J48.0001.Kappa': 0.7043302166347443,\n",
       "  'J48.001.AUC': 0.9391585368767195,\n",
       "  'J48.001.ErrRate': 0.10356347438752785,\n",
       "  'J48.001.Kappa': 0.7043302166347443,\n",
       "  'MajorityClassPercentage': 76.16926503340757,\n",
       "  'MajorityClassSize': 684.0,\n",
       "  'MaxAttributeEntropy': 1.8215224482924186,\n",
       "  'MaxKurtosisOfNumericAtts': 13.215477213878724,\n",
       "  'MaxMeansOfNumericAtts': 1263.0946547884187,\n",
       "  'MaxMutualInformation': 0.40908953764451,\n",
       "  'MaxNominalAttDistinctValues': 7.0,\n",
       "  'MaxSkewnessOfNumericAtts': 3.7616019689156888,\n",
       "  'MaxStdDevOfNumericAtts': 1871.3991072665933,\n",
       "  'MeanAttributeEntropy': 0.2515351603742048,\n",
       "  'MeanKurtosisOfNumericAtts': 4.6480244352098286,\n",
       "  'MeanMeansOfNumericAtts': 348.50426818856715,\n",
       "  'MeanMutualInformation': 0.044331968697414056,\n",
       "  'MeanNoiseToSignalRatio': 4.673900071775454,\n",
       "  'MeanNominalAttDistinctValues': 1.6363636363636362,\n",
       "  'MeanSkewnessOfNumericAtts': 2.0269825910719437,\n",
       "  'MeanStdDevOfNumericAtts': 405.17326983791025,\n",
       "  'MinAttributeEntropy': -0.0,\n",
       "  'MinKurtosisOfNumericAtts': -0.9723842038435437,\n",
       "  'MinMeansOfNumericAtts': 1.1985489977728285,\n",
       "  'MinMutualInformation': 0.0,\n",
       "  'MinNominalAttDistinctValues': 0.0,\n",
       "  'MinSkewnessOfNumericAtts': 0.07299048442083138,\n",
       "  'MinStdDevOfNumericAtts': 0.871208280971892,\n",
       "  'MinorityClassPercentage': 0.8908685968819599,\n",
       "  'MinorityClassSize': 8.0,\n",
       "  'NaiveBayesAUC': 0.9315907109421729,\n",
       "  'NaiveBayesErrRate': 0.24610244988864144,\n",
       "  'NaiveBayesKappa': 0.5569590016631507,\n",
       "  'NumberOfBinaryFeatures': 4.0,\n",
       "  'NumberOfClasses': 5.0,\n",
       "  'NumberOfFeatures': 39.0,\n",
       "  'NumberOfInstances': 898.0,\n",
       "  'NumberOfInstancesWithMissingValues': 898.0,\n",
       "  'NumberOfMissingValues': 22175.0,\n",
       "  'NumberOfNumericFeatures': 6.0,\n",
       "  'NumberOfSymbolicFeatures': 33.0,\n",
       "  'PercentageOfBinaryFeatures': 10.256410256410255,\n",
       "  'PercentageOfInstancesWithMissingValues': 100.0,\n",
       "  'PercentageOfMissingValues': 63.317343384158534,\n",
       "  'PercentageOfNumericFeatures': 15.384615384615385,\n",
       "  'PercentageOfSymbolicFeatures': 84.61538461538461,\n",
       "  'Quartile1AttributeEntropy': 0.0,\n",
       "  'Quartile1KurtosisOfNumericAtts': -0.40305022089010156,\n",
       "  'Quartile1MeansOfNumericAtts': 3.025695155902005,\n",
       "  'Quartile1MutualInformation': 0.0,\n",
       "  'Quartile1SkewnessOfNumericAtts': 0.967384603629726,\n",
       "  'Quartile1StdDevOfNumericAtts': 10.505435772171138,\n",
       "  'Quartile2AttributeEntropy': 0.0,\n",
       "  'Quartile2KurtosisOfNumericAtts': 1.6372437439142264,\n",
       "  'Quartile2MeansOfNumericAtts': 21.222160356347437,\n",
       "  'Quartile2MutualInformation': 0.0,\n",
       "  'Quartile2SkewnessOfNumericAtts': 1.6547313364025702,\n",
       "  'Quartile2StdDevOfNumericAtts': 69.85338529046133,\n",
       "  'Quartile3AttributeEntropy': 0.2385631077559124,\n",
       "  'Quartile3KurtosisOfNumericAtts': 12.741748058445403,\n",
       "  'Quartile3MeansOfNumericAtts': 901.2636692650334,\n",
       "  'Quartile3MutualInformation': 0.0206465881071925,\n",
       "  'Quartile3SkewnessOfNumericAtts': 3.7546438249219056,\n",
       "  'Quartile3StdDevOfNumericAtts': 771.8590427889504,\n",
       "  'REPTreeDepth1AUC': 0.962680369298288,\n",
       "  'REPTreeDepth1ErrRate': 0.08463251670378619,\n",
       "  'REPTreeDepth1Kappa': 0.768583383630482,\n",
       "  'REPTreeDepth2AUC': 0.962680369298288,\n",
       "  'REPTreeDepth2ErrRate': 0.08463251670378619,\n",
       "  'REPTreeDepth2Kappa': 0.768583383630482,\n",
       "  'REPTreeDepth3AUC': 0.962680369298288,\n",
       "  'REPTreeDepth3ErrRate': 0.08463251670378619,\n",
       "  'REPTreeDepth3Kappa': 0.768583383630482,\n",
       "  'RandomTreeDepth1AUC': 0.9296999989655875,\n",
       "  'RandomTreeDepth1ErrRate': 0.0801781737193764,\n",
       "  'RandomTreeDepth1Kappa': 0.7953250436852635,\n",
       "  'RandomTreeDepth2AUC': 0.9296999989655875,\n",
       "  'RandomTreeDepth2ErrRate': 0.0801781737193764,\n",
       "  'RandomTreeDepth2Kappa': 0.7953250436852635,\n",
       "  'RandomTreeDepth3AUC': 0.9296999989655875,\n",
       "  'RandomTreeDepth3ErrRate': 0.0801781737193764,\n",
       "  'RandomTreeDepth3Kappa': 0.7953250436852635,\n",
       "  'StdvNominalAttDistinctValues': 1.5576059718800395,\n",
       "  'kNN1NAUC': 0.8721948540771287,\n",
       "  'kNN1NErrRate': 0.06347438752783964,\n",
       "  'kNN1NKappa': 0.8261102938928316},\n",
       " 'data_pickle_file': None,\n",
       " 'data_feather_file': None,\n",
       " 'feather_attribute_file': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a29f01",
   "metadata": {},
   "source": [
    "From the vars() output, we can see quite a bit more information about the dataset than what the OpenML object reported. While some of this may seem unnecessary (md5checksum, for example), it may still be beneficial to have for later analysis (who is contributing the most to these platforms and how reusable are their contributions?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29dbe4",
   "metadata": {},
   "source": [
    "In addition to the vars() function for listing the actual data attributes, we can take a look at the dir() function. The dir() function returns a list of all of the attributes and methods for an object \\[2\\]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ae12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset_dir = dir(sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba735cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_apply_repr_template',\n",
       " '_cache_compressed_file_from_file',\n",
       " '_compressed_cache_file_paths',\n",
       " '_convert_array_format',\n",
       " '_dataset',\n",
       " '_download_data',\n",
       " '_entity_letter',\n",
       " '_get_arff',\n",
       " '_get_file_elements',\n",
       " '_get_repr_body_fields',\n",
       " '_load_data',\n",
       " '_minio_url',\n",
       " '_parse_data_from_arff',\n",
       " '_parse_publish_response',\n",
       " '_to_dict',\n",
       " '_to_xml',\n",
       " '_unpack_categories',\n",
       " 'cache_format',\n",
       " 'citation',\n",
       " 'collection_date',\n",
       " 'contributor',\n",
       " 'creator',\n",
       " 'data_feather_file',\n",
       " 'data_file',\n",
       " 'data_pickle_file',\n",
       " 'dataset_id',\n",
       " 'default_target_attribute',\n",
       " 'description',\n",
       " 'feather_attribute_file',\n",
       " 'features',\n",
       " 'format',\n",
       " 'get_data',\n",
       " 'get_features_by_type',\n",
       " 'id',\n",
       " 'ignore_attribute',\n",
       " 'language',\n",
       " 'licence',\n",
       " 'md5_checksum',\n",
       " 'name',\n",
       " 'open_in_browser',\n",
       " 'openml_url',\n",
       " 'original_data_url',\n",
       " 'paper_url',\n",
       " 'parquet_file',\n",
       " 'publish',\n",
       " 'push_tag',\n",
       " 'qualities',\n",
       " 'remove_tag',\n",
       " 'retrieve_class_labels',\n",
       " 'row_id_attribute',\n",
       " 'tag',\n",
       " 'update_comment',\n",
       " 'upload_date',\n",
       " 'url',\n",
       " 'url_for_id',\n",
       " 'version',\n",
       " 'version_label',\n",
       " 'visibility']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26bb577",
   "metadata": {},
   "source": [
    "From this, we see all of the previous object attribute names, along with all of the functions available to the object's class. While this may not seem any more beneficial than the vars() function for the purpose of retrieving information from the object, it does allow us to squeeze out a couple more variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "974c0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(obj):\n",
    "    attributes = [attr for attr in dir(obj) if \n",
    "                           not hasattr(getattr(obj, attr), '__call__')\n",
    "                           and not attr.startswith('_')]\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e53d78",
   "metadata": {},
   "source": [
    "We use the get_attributes() function as a way to retrieve attribute names from dir() that may or may not have been available from vars(). This function works by taking all of the attributes listed from dir() and returning all of the ones that \n",
    "1. are not functions (are unable to be \"called\") and \n",
    "2. are not private to the class (don't start with a leading underscore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52fd3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_attributes = get_attributes(sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4696c3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id', 'openml_url'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset_attributes).difference(sample_dataset_vars.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eec8fb",
   "metadata": {},
   "source": [
    "Although the only differences between the attributes we scrape from dir() and the attributes presented from vars() seem to be relatively unuseful (as the id is present again as the dataset_id, and we currently do not have a use for the url's), the cost of retrieving our data in this way is low compared to the cost of the rest of the data querying. We can also take a look at what additional attributes are provided when using this method for runs and tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0152c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list = openml.runs.list_runs(size=2)\n",
    "task_list = openml.tasks.list_tasks(size=2)\n",
    "\n",
    "# This is the same functionality for extracting a run/task & querying the id as was done for datasets,\n",
    "# but we condense the code a bit for brevity. Note that we index at 1 instead of 0 due to an error in the way\n",
    "# OpenML stores the run associated with the first run_id\n",
    "\n",
    "sample_run_info = run_list[list(run_list.keys())[1]]\n",
    "sample_run_id = sample_run_info['run_id']\n",
    "\n",
    "sample_task_info = task_list[list(task_list.keys())[0]]\n",
    "sample_task_id = sample_task_info['tid']\n",
    "\n",
    "sample_run = openml.runs.get_run(sample_run_id)\n",
    "sample_task = openml.tasks.get_task(sample_task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47728561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_id': 2,\n",
       " 'task_id': 72,\n",
       " 'setup_id': 16,\n",
       " 'flow_id': 75,\n",
       " 'uploader': 1,\n",
       " 'task_type': <TaskType.LEARNING_CURVE: 3>,\n",
       " 'upload_time': '2014-04-06 23:31:13',\n",
       " 'error_message': ''}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_run_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "535e8c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tid': 2,\n",
       " 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>,\n",
       " 'did': 2,\n",
       " 'name': 'anneal',\n",
       " 'task_type': 'Supervised Classification',\n",
       " 'status': 'active',\n",
       " 'estimation_procedure': '10-fold Crossvalidation',\n",
       " 'evaluation_measures': 'predictive_accuracy',\n",
       " 'source_data': '2',\n",
       " 'target_feature': 'class',\n",
       " 'MajorityClassSize': 684,\n",
       " 'MaxNominalAttDistinctValues': 7,\n",
       " 'MinorityClassSize': 8,\n",
       " 'NumberOfClasses': 5,\n",
       " 'NumberOfFeatures': 39,\n",
       " 'NumberOfInstances': 898,\n",
       " 'NumberOfInstancesWithMissingValues': 898,\n",
       " 'NumberOfMissingValues': 22175,\n",
       " 'NumberOfNumericFeatures': 6,\n",
       " 'NumberOfSymbolicFeatures': 33}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_task_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5ce15",
   "metadata": {},
   "source": [
    "We can take a look at the sample run and sample task to get an understanding of what data is present in those objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d82cadc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenML Run\n",
       "==========\n",
       "Uploader Name...: Jan van Rijn\n",
       "Uploader Profile: https://www.openml.org/u/1\n",
       "Metric..........: predictive_accuracy\n",
       "Result..........: 0.7136363636363636\n",
       "Run ID..........: 2\n",
       "Run URL.........: https://www.openml.org/r/2\n",
       "Task ID.........: 72\n",
       "Task Type.......: Learning Curve\n",
       "Task URL........: https://www.openml.org/t/72\n",
       "Flow ID.........: 75\n",
       "Flow Name.......: weka.AdaBoostM1_DecisionStump(1)\n",
       "Flow URL........: https://www.openml.org/f/75\n",
       "Setup ID........: 16\n",
       "Setup String....: weka.classifiers.meta.AdaBoostM1 -- -P 100 -S 1 -I 10 -W weka.classifiers.trees.DecisionStump\n",
       "Dataset ID......: 13\n",
       "Dataset URL.....: https://www.openml.org/d/13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61a38838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenML Classification Task\n",
       "==========================\n",
       "Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION\n",
       "Task ID..............: 2\n",
       "Task URL.............: https://www.openml.org/t/2\n",
       "Estimation Procedure.: crossvalidation\n",
       "Evaluation Measure...: predictive_accuracy\n",
       "Target Feature.......: class\n",
       "# of Classes.........: 6\n",
       "Cost Matrix..........: Available"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d29c4673",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_attributes = get_attributes(sample_run)\n",
    "task_attributes = get_attributes(sample_task)\n",
    "\n",
    "sample_run_vars = vars(sample_run)\n",
    "sample_task_vars = vars(sample_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5cbdad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uploader': 1,\n",
       " 'uploader_name': 'Jan van Rijn',\n",
       " 'task_id': 72,\n",
       " 'task_type': 'Learning Curve',\n",
       " 'task_evaluation_measure': 'predictive_accuracy',\n",
       " 'flow_id': 75,\n",
       " 'flow_name': 'weka.AdaBoostM1_DecisionStump(1)',\n",
       " 'setup_id': 16,\n",
       " 'setup_string': 'weka.classifiers.meta.AdaBoostM1 -- -P 100 -S 1 -I 10 -W weka.classifiers.trees.DecisionStump',\n",
       " 'parameter_settings': [OrderedDict([('oml:name', 'I'),\n",
       "               ('oml:value', '10'),\n",
       "               ('oml:component', '75')]),\n",
       "  OrderedDict([('oml:name', 'P'),\n",
       "               ('oml:value', '100'),\n",
       "               ('oml:component', '75')]),\n",
       "  OrderedDict([('oml:name', 'S'),\n",
       "               ('oml:value', '1'),\n",
       "               ('oml:component', '75')]),\n",
       "  OrderedDict([('oml:name', 'W'),\n",
       "               ('oml:value', 'weka.classifiers.trees.DecisionStump'),\n",
       "               ('oml:component', '75')])],\n",
       " 'dataset_id': 13,\n",
       " 'evaluations': OrderedDict([('area_under_roc_curve', 0.6867257828504536),\n",
       "              ('average_cost', 0.0),\n",
       "              ('f_measure', 0.6972485639430557),\n",
       "              ('kappa', 0.25065262457451437),\n",
       "              ('kb_relative_information_score', 0.13296871639575372),\n",
       "              ('mean_absolute_error', 0.3535431650349649),\n",
       "              ('mean_prior_absolute_error', 0.41831779331778546),\n",
       "              ('number_of_instances', 2860.0),\n",
       "              ('os_information',\n",
       "               '[ Oracle Corporation, 1.7.0_51, amd64, Linux, 3.7.10-1.28-desktop ]'),\n",
       "              ('precision', 0.6927926061750754),\n",
       "              ('predictive_accuracy', 0.7136363636363636),\n",
       "              ('prior_entropy', 0.877851532271762),\n",
       "              ('recall', 0.7136363636363636),\n",
       "              ('relative_absolute_error', 0.8451544990016409),\n",
       "              ('root_mean_prior_squared_error', 0.45702874951767164),\n",
       "              ('root_mean_squared_error', 0.4375142654343472),\n",
       "              ('root_relative_squared_error', 0.9573014080538278),\n",
       "              ('scimark_benchmark', 1967.305328662524),\n",
       "              ('total_cost', 0.0)]),\n",
       " 'fold_evaluations': OrderedDict(),\n",
       " 'sample_evaluations': OrderedDict(),\n",
       " 'data_content': None,\n",
       " 'output_files': OrderedDict([('description', 65), ('predictions', 66)]),\n",
       " 'trace': None,\n",
       " 'error_message': None,\n",
       " 'task': None,\n",
       " 'flow': None,\n",
       " 'run_id': 2,\n",
       " 'model': None,\n",
       " 'tags': ['testing'],\n",
       " 'predictions_url': 'https://www.openml.org/data/download/66/weka_generated_predictions3181957963973800253.arff',\n",
       " 'description_text': None,\n",
       " 'run_details': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_run_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1cd30d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 2,\n",
       " 'task_type_id': <TaskType.SUPERVISED_CLASSIFICATION: 1>,\n",
       " 'task_type': 'Supervised Classification',\n",
       " 'dataset_id': 2,\n",
       " 'evaluation_measure': 'predictive_accuracy',\n",
       " 'estimation_procedure': {'type': 'crossvalidation',\n",
       "  'parameters': {'number_repeats': '1',\n",
       "   'number_folds': '10',\n",
       "   'percentage': '',\n",
       "   'stratified_sampling': 'true'},\n",
       "  'data_splits_url': 'https://www.openml.org/api_splits/get/2/Task_2_splits.arff'},\n",
       " 'estimation_procedure_id': 1,\n",
       " 'split': None,\n",
       " 'target_name': 'class',\n",
       " 'class_labels': ['1', '2', '3', '4', '5', 'U'],\n",
       " 'cost_matrix': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_task_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "519d029e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id', 'openml_url'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(run_attributes).difference(sample_run_vars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79a9d969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimation_parameters', 'id', 'openml_url'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(task_attributes).difference(sample_task_vars.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1524221d",
   "metadata": {},
   "source": [
    "We see that for runs, we again don't retrieve any additional useful information. However, we now get the estimation parameters used for running tasks, which is useful for purposes of reuse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6894f9cd",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f647137",
   "metadata": {},
   "source": [
    "Since the evaluations work flow is a bit different, lets also take a look at the information that we retrieve when using the dir() and vars() functions for the evaluation objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34076f67",
   "metadata": {},
   "source": [
    "While the datasets/runs/tasks did not require any information when listing, we are required to provide an evaluation measure when listing evaluations. To do this, we first query the different evaluation measures available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4242b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_measures = openml.evaluations.list_evaluation_measures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3cc3c",
   "metadata": {},
   "source": [
    "We can then use one of the evaluations returned to retrieve some evaluations of that type using the list_evaluations() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d7089e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_measure = evaluation_measures[0]\n",
    "evaluation_list = openml.evaluations.list_evaluations(sample_measure, size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5299000d",
   "metadata": {},
   "source": [
    "Similar to before, we grab one of the OrderedDict keys and take a look at an example evaluation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13881c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_list_keys = evaluation_list.keys()\n",
    "sample_evaluation_key = list(evaluation_list_keys)[0]\n",
    "sample_evaluation_info = evaluation_list[sample_evaluation_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92d15573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenML Evaluation\n",
       "=================\n",
       "Run ID.........: 62\n",
       "OpenML Run URL.: https://www.openml.org/r/62\n",
       "Task ID........: 1\n",
       "OpenML Flow URL: https://www.openml.org/f/76\n",
       "Setup ID.......: 17\n",
       "Data ID........: 1\n",
       "Data Name......: anneal\n",
       "OpenML Data URL: https://www.openml.org/d/1\n",
       "Metric Used....: area_under_roc_curve\n",
       "Result.........: 0.995034"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_evaluation_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55435d0b",
   "metadata": {},
   "source": [
    "Taking a look at a sample evaluation, we can see that this is different than what was returned from the list_datasets() function. Instead of a dictionary containing information, we recieve an OpenML object, similar to what was returned for the get_dataset() function. The evaluations do not have a list_evaluations() function that returns any additional information, so this is the terminal result that we can retrieve. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd626a2a",
   "metadata": {},
   "source": [
    "Again, let's take a look at what the vars() and dir() functions give us for this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e261d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_evaluation_vars = vars(sample_evaluation_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3575d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_id': 62,\n",
       " 'task_id': 1,\n",
       " 'setup_id': 17,\n",
       " 'flow_id': 76,\n",
       " 'flow_name': 'weka.Bagging_REPTree(1)',\n",
       " 'data_id': 1,\n",
       " 'data_name': 'anneal',\n",
       " 'function': 'area_under_roc_curve',\n",
       " 'upload_time': '2014-04-06 23:57:45',\n",
       " 'uploader': 1,\n",
       " 'uploader_name': 'Jan van Rijn',\n",
       " 'value': 0.995034,\n",
       " 'values': None,\n",
       " 'array_data': '[0.93111,0.999975,0.994856,0.0,1,0.990326]'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_evaluation_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fac0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_evaluation_dir = dir(sample_evaluation_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87a6c6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'array_data',\n",
       " 'data_id',\n",
       " 'data_name',\n",
       " 'flow_id',\n",
       " 'flow_name',\n",
       " 'function',\n",
       " 'run_id',\n",
       " 'setup_id',\n",
       " 'task_id',\n",
       " 'upload_time',\n",
       " 'uploader',\n",
       " 'uploader_name',\n",
       " 'value',\n",
       " 'values']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_evaluation_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9908de",
   "metadata": {},
   "source": [
    "The dir() results for the sample evaluation don't appear to provide much more useful information than what is present in the vars, but let's take a look at what attributes we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aab1a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_attributes = get_attributes(sample_evaluation_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dcb4a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(evaluation_attributes).difference(sample_evaluation_vars.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bcf2bd",
   "metadata": {},
   "source": [
    "As hinted at above, there is actually no difference between retrieving attributes with our own functionality versus simply using the vars function to retrieve the data for us. Because of this, the evaluations portion of our code utilizes the vars() functionality instead as a time-saving measure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
