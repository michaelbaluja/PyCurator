{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from flatten_json import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check contents of directory\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An access token must be included in all requests as either a URL parameter (access_token) or HTTP request header (Authorization)\n",
    "\n",
    "#GET /api/deposit/depositions?access_token=<ACCESS_TOKEN>\n",
    "\n",
    "#GET /api/deposit/depositions\n",
    "#Authorization: Bearer <ACCESS_TOKEN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pesonal access token, stored in Zenodo_access_token.py\n",
    "!python 'Zenodo_access_token.py'\n",
    "#not sure why this isn't working?? the file is definitely there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this works in the meantime\n",
    "exec(open(\"Zenodo_access_token.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that loaded ACCESS_TOKEN variable\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General Zenodo requests format\n",
    "#response = requests.get('https://zenodo.org/api/records',\n",
    "#                        params={'q': 'my title',\n",
    "#                                'access_token': ACCESS_TOKEN})\n",
    "#print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example search\n",
    "response = requests.get('https://zenodo.org/api/records',\n",
    "                        params={'q': 'machine learning',\n",
    "                                'access_token': ACCESS_TOKEN})\n",
    "#print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY NOTES\n",
    "\n",
    "#exploring with Postman - GET https://zenodo.org/api/records/?sort=bestmatch&q=machine+learning&page=2&size=10\n",
    "#looks like results are paginated, so need to get total number of pages, then go through\n",
    "#can have size up to max of 100 (100 results per page looks like)\n",
    "\n",
    "#first section of json is summary of results (number by file type, format, etc)\n",
    "#\"aggregations\" section\n",
    "#this is good info - want to extract as separate summary table\n",
    "\n",
    "#the section with details is \"hits\"\n",
    "#we want to extract and collapse to have hits metadata as tabular form\n",
    "\n",
    "#can extract downloads - downstream, could filter to top 200 objects by most downloaded \n",
    "#(for those that aren't just papers, but actually include other components)\n",
    "\n",
    "#will need to filter by access rights\n",
    "#do we want everything, or just \"open\"?\n",
    "#do we just want most recent version? (probably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLLAPSE METHOD 1\n",
    "\n",
    "#collapse json using flatten_json (https://github.com/amirziai/flatten)\n",
    "zenodo_search = flatten(response.json())\n",
    "print(zenodo_search)\n",
    "\n",
    "#this is a FULL collapse - good start but not quite what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(zenodo_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLLAPSE METHOD 2\n",
    "\n",
    "#alternate flattening pandas method\n",
    "zenodo_search_pd = pd.io.json.json_normalize(response.json())\n",
    "zenodo_search_pd\n",
    "\n",
    "#potential for splitting out aggregation vs hits\n",
    "#could split into two dfs and then continue to collapse to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLLAPSE METHOD 3\n",
    "\n",
    "#We want something like this (maybe?): https://github.com/amirziai/flatten\n",
    "\n",
    "dic = [\n",
    "    {\"a\": 1, \"b\": 2, \"c\": {\"d\": 3, \"e\": 4}},\n",
    "    {\"a\": 0.5, \"c\": {\"d\": 3.2}},\n",
    "    {\"a\": 0.8, \"b\": 1.8},\n",
    "]\n",
    "\n",
    "dic_flattened = [flatten(d) for d in dic]\n",
    "\n",
    "df = pd.DataFrame(dic_flattened)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
