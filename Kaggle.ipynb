{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilizes the Kaggle API. Follow these steps in order to get the necessary credentials to continue:\n",
    "\n",
    "1. Sign up for a Kaggle account at https://www.kaggle.com.\n",
    "2. Go to the 'Account' tab of your user profile - ```https://www.kaggle.com/{username}/account```.\n",
    "3. Select 'Create New API Token' under 'API' section.\n",
    "    - This will trigger the download of kaggle.json, a file containing your API credentials. \n",
    "4. Place this file in the location:\n",
    "    - ~/.kaggle/kaggle.json (for macOS/unix)\n",
    "    - C:\\Users\\<Windows-username>\\.kaggle\\kaggle.json (for Windows) \n",
    "    - You can check the exact location, sans drive, with echo %HOMEPATH%). \n",
    "    - You can define a shell environment variable KAGGLE_CONFIG_DIR to change this location to:\n",
    "        - $KAGGLE_CONFIG_DIR/kaggle.json (for macOS/unix)\n",
    "        - %KAGGLE_CONFIG_DIR%\\kaggle.json (for Windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation Guide:\n",
    "- Kaggle API ([Kaggle](https://www.kaggle.com/docs/api))\n",
    "- Kaggle API ([GitHub](https://github.com/Kaggle/kaggle-api)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import kaggle, installing if necessary\n",
    "try:\n",
    "    import kaggle\n",
    "except ImportError as e:\n",
    "    !pip3 install kaggle\n",
    "    import kaggle\n",
    "    \n",
    "import subprocess # Used to run unix commands\n",
    "import pandas as pd # For storing/manipulating command data\n",
    "from io import StringIO # Lets us read csv string output from command into DataFrame\n",
    "import json # Reading back the metadata files\n",
    "from tqdm import tqdm # Gives status bar on loop completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting/extracting dataset names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_output(search_terms, search_type):\n",
    "    '''\n",
    "    Calls the Kaggle API with the specified query terms and returns the search output results.\n",
    "    \n",
    "    Params:\n",
    "    - search_terms (str/list-like): string or list of strings that should be searched for\n",
    "    - search_type (str): objects to search over (must be either datasets or kernels)\n",
    "    \n",
    "    Returns:\n",
    "    - cumulative_output (str): output from all searches\n",
    "    '''\n",
    "    # Make sure our input is valid\n",
    "    assert len(search_terms) > 0, 'Please enter non-empty search terms'\n",
    "    assert search_type in ('datasets', 'kernels'), 'Search can only be conducted over datasets or kernels'\n",
    "    \n",
    "    # If a singular search term is provided as a string, need to wrap it in a list\n",
    "    if type(search_terms) == str:\n",
    "        search_terms = [search_terms]\n",
    "    \n",
    "    # Set search parameters\n",
    "    page_idx = 1\n",
    "    search_output = ''\n",
    "    cumulative_output = ''\n",
    "    completion_phrase = f'No {search_type} found\\n'\n",
    "    \n",
    "    # Search for each term\n",
    "    for search_term in tqdm(search_terms):\n",
    "        # Pulls the records for a single page of datasets for the given search term\n",
    "        # Runs the command, captures the output in stdout, reads it from stdout, and decodes it to str from binary\n",
    "        search_output = subprocess.run(['kaggle', search_type, 'list', '-v',\n",
    "                                         '-s', f'\"{search_term}\"', \n",
    "                                         '-p', str(page_idx)], \n",
    "                                        capture_output=True).stdout.decode()\n",
    "        \n",
    "        # Once we no longer see new output, we stop\n",
    "        while search_output != completion_phrase:\n",
    "            # Accumulate the output\n",
    "            cumulative_output = cumulative_output + search_output\n",
    "\n",
    "            # Increments the page count for searching\n",
    "            page_idx += 1\n",
    "            \n",
    "            # Pulls the records for a single page of datasets for the given search term\n",
    "            # Runs the command, captures the output in stdout, reads it from stdout, and decodes it to str from binary\n",
    "            search_output = subprocess.run(['kaggle', search_type, 'list', '-v',\n",
    "                                             '-s', f'\"{search_term}\"', \n",
    "                                             '-p', str(page_idx)], \n",
    "                                            capture_output=True).stdout.decode()\n",
    "            \n",
    "            # Remove header row\n",
    "            if search_output != completion_phrase:\n",
    "                search_output = '\\r\\n'.join(search_output.split('\\r\\n')[1::])\n",
    "        \n",
    "    return cumulative_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_csv_output_to_dataframe(output):\n",
    "    '''\n",
    "    Given a string variable in csv format, returns a Pandas DataFrame\n",
    "    \n",
    "    Params:\n",
    "    - output (str): csv-styled string to be converted\n",
    "    \n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): DataFrame consisting of data from 'output' string variable\n",
    "    '''\n",
    "    # Create DataFrame of results\n",
    "    output = StringIO(output)\n",
    "    df = pd.read_csv(output)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['korea']\n",
    "search_type = 'datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.32s/it]\n"
     ]
    }
   ],
   "source": [
    "search_output = get_search_output(search_terms, search_type)\n",
    "search_output_df = convert_string_csv_output_to_dataframe(search_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kimjihoo/coronavirusdataset</td>\n",
       "      <td>[NeurIPS 2020] Data Science for COVID-19 (DS4C)</td>\n",
       "      <td>7MB</td>\n",
       "      <td>2020-07-13 14:07:31</td>\n",
       "      <td>82997</td>\n",
       "      <td>1465</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bappekim/air-pollution-in-seoul</td>\n",
       "      <td>Air Pollution in Seoul</td>\n",
       "      <td>20MB</td>\n",
       "      <td>2020-04-03 16:33:49</td>\n",
       "      <td>9741</td>\n",
       "      <td>309</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bappekim/south-korea-visitors</td>\n",
       "      <td>South Korea Visitors</td>\n",
       "      <td>99KB</td>\n",
       "      <td>2020-06-04 08:53:36</td>\n",
       "      <td>1027</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hongsean/korea-income-and-welfare</td>\n",
       "      <td>Korea Income and Welfare</td>\n",
       "      <td>772KB</td>\n",
       "      <td>2020-12-20 13:05:27</td>\n",
       "      <td>568</td>\n",
       "      <td>15</td>\n",
       "      <td>0.970588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bryanpark/korean-single-speaker-speech-dataset</td>\n",
       "      <td>Korean Single Speaker Speech Dataset</td>\n",
       "      <td>3GB</td>\n",
       "      <td>2020-03-15 08:56:42</td>\n",
       "      <td>5469</td>\n",
       "      <td>106</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>llkdev/gender-data</td>\n",
       "      <td>Gender Data</td>\n",
       "      <td>2MB</td>\n",
       "      <td>2019-06-14 08:08:16</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>chenykfrank/immc21</td>\n",
       "      <td>immc21</td>\n",
       "      <td>94KB</td>\n",
       "      <td>2021-02-03 15:21:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>anuragshakya2005/gas-prices</td>\n",
       "      <td>gas_prices</td>\n",
       "      <td>690B</td>\n",
       "      <td>2020-11-18 10:57:15</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>gremmn/gas-prices</td>\n",
       "      <td>gas prices</td>\n",
       "      <td>685B</td>\n",
       "      <td>2021-01-20 12:59:28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>theeranartmeesathien/covid-dataset-for-prediction</td>\n",
       "      <td>Covid dataset for prediction</td>\n",
       "      <td>1MB</td>\n",
       "      <td>2021-06-06 12:09:03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "0                          kimjihoo/coronavirusdataset   \n",
       "1                      bappekim/air-pollution-in-seoul   \n",
       "2                        bappekim/south-korea-visitors   \n",
       "3                    hongsean/korea-income-and-welfare   \n",
       "4       bryanpark/korean-single-speaker-speech-dataset   \n",
       "..                                                 ...   \n",
       "169                                 llkdev/gender-data   \n",
       "170                                 chenykfrank/immc21   \n",
       "171                        anuragshakya2005/gas-prices   \n",
       "172                                  gremmn/gas-prices   \n",
       "173  theeranartmeesathien/covid-dataset-for-prediction   \n",
       "\n",
       "                                               title   size  \\\n",
       "0    [NeurIPS 2020] Data Science for COVID-19 (DS4C)    7MB   \n",
       "1                             Air Pollution in Seoul   20MB   \n",
       "2                               South Korea Visitors   99KB   \n",
       "3                           Korea Income and Welfare  772KB   \n",
       "4               Korean Single Speaker Speech Dataset    3GB   \n",
       "..                                               ...    ...   \n",
       "169                                      Gender Data    2MB   \n",
       "170                                           immc21   94KB   \n",
       "171                                       gas_prices   690B   \n",
       "172                                       gas prices   685B   \n",
       "173                     Covid dataset for prediction    1MB   \n",
       "\n",
       "             lastUpdated  downloadCount  voteCount  usabilityRating  \n",
       "0    2020-07-13 14:07:31          82997       1465         1.000000  \n",
       "1    2020-04-03 16:33:49           9741        309         1.000000  \n",
       "2    2020-06-04 08:53:36           1027         24         1.000000  \n",
       "3    2020-12-20 13:05:27            568         15         0.970588  \n",
       "4    2020-03-15 08:56:42           5469        106         0.750000  \n",
       "..                   ...            ...        ...              ...  \n",
       "169  2019-06-14 08:08:16              8          0         0.125000  \n",
       "170  2021-02-03 15:21:36              0          0         0.117647  \n",
       "171  2020-11-18 10:57:15             41          1         0.117647  \n",
       "172  2021-01-20 12:59:28             12          0         0.117647  \n",
       "173  2021-06-06 12:09:03              0          0         0.352941  \n",
       "\n",
       "[174 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling dataset metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Unable to find a way to store metadata in memory as opposed to saving file, but this workaround appears to be functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _retrieve_metadata_json(dataset_path):\n",
    "    '''\n",
    "    Queries Kaggle for metadata json file & returns the json data as a dictionary\n",
    "    \n",
    "    Params:\n",
    "    - dataset_path (str): path for the dataset\n",
    "    \n",
    "    Returns:\n",
    "    - metadata_dict (dict): dictionary containing json metadata\n",
    "    '''\n",
    "    # Download the metadata\n",
    "    subprocess.run(['kaggle', 'datasets', 'metadata', dataset_path])\n",
    "\n",
    "    # Access the metadata and load it in as a dictionary\n",
    "    with open('dataset-metadata.json') as file:\n",
    "        json_data = json.load(file)\n",
    "        \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(dataset_paths):\n",
    "    '''\n",
    "    Retrieves the metadata for the file/files listed in dataset_paths\n",
    "    \n",
    "    Params:\n",
    "    - dataset_paths (str/list-like): string or list of strings containing the paths for the datasets\n",
    "    \n",
    "    Returns:\n",
    "    - metadata_df (pandas.DataFrame): DataFrame containing metadata for the requested datasets\n",
    "    '''\n",
    "    # Make sure our input is valid\n",
    "    assert len(dataset_paths) > 0, 'Please enter at least one dataset path'\n",
    "    \n",
    "    # If a singular search term is provided as a string, need to wrap it in a list\n",
    "    if type(dataset_paths) == str:\n",
    "        dataset_paths = [dataset_paths]\n",
    "        \n",
    "    # Run first query\n",
    "    json_data = _retrieve_metadata_json(dataset_paths[0])\n",
    "        \n",
    "    # Create DataFrame to store metadata in, using columns found in first query, and then add query info\n",
    "    metadata_df = pd.DataFrame(columns=json_data.keys(), dtype=object)\n",
    "    metadata_df = metadata_df.append(json_data, ignore_index=True)\n",
    "        \n",
    "    # Pulls metadata information for each dataset found above\n",
    "    for dataset_path in tqdm(dataset_paths[1::]):\n",
    "        # Download & load the metadata\n",
    "        json_data = _retrieve_metadata_json(dataset_path)\n",
    "\n",
    "        # Store the metadata into our DataFrame created above\n",
    "        metadata_df = metadata_df.append(json_data, ignore_index=True)\n",
    "        \n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [03:14<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_paths = search_output_df.ref.values\n",
    "metadata_df = get_metadata(dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_no</th>\n",
       "      <th>datasetId</th>\n",
       "      <th>datasetSlug</th>\n",
       "      <th>ownerUser</th>\n",
       "      <th>usabilityRating</th>\n",
       "      <th>totalViews</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>totalDownloads</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>description</th>\n",
       "      <th>isPrivate</th>\n",
       "      <th>keywords</th>\n",
       "      <th>licenses</th>\n",
       "      <th>collaborators</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kimjihoo/coronavirusdataset</td>\n",
       "      <td>527325</td>\n",
       "      <td>527325</td>\n",
       "      <td>coronavirusdataset</td>\n",
       "      <td>kimjihoo</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>490936</td>\n",
       "      <td>1465</td>\n",
       "      <td>82997</td>\n",
       "      <td>[NeurIPS 2020] Data Science for COVID-19 (DS4C)</td>\n",
       "      <td>DS4C: Data Science for COVID-19 in South Korea</td>\n",
       "      <td>### A portion of our dataset has been accepted...</td>\n",
       "      <td>False</td>\n",
       "      <td>[universities and colleges, biology, data visu...</td>\n",
       "      <td>[{'name': 'CC-BY-NC-SA-4.0'}]</td>\n",
       "      <td>[{'username': 'kjm0623v', 'role': 'writer'}, {...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bappekim/air-pollution-in-seoul</td>\n",
       "      <td>576393</td>\n",
       "      <td>576393</td>\n",
       "      <td>air-pollution-in-seoul</td>\n",
       "      <td>bappekim</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>81243</td>\n",
       "      <td>309</td>\n",
       "      <td>9741</td>\n",
       "      <td>Air Pollution in Seoul</td>\n",
       "      <td>Air Pollution Measurement Information in Seoul...</td>\n",
       "      <td>### Context\\nThis dataset deals with air pollu...</td>\n",
       "      <td>False</td>\n",
       "      <td>[earth and nature, environment, pollution]</td>\n",
       "      <td>[{'name': 'CC-BY-SA-4.0'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bappekim/south-korea-visitors</td>\n",
       "      <td>692628</td>\n",
       "      <td>692628</td>\n",
       "      <td>south-korea-visitors</td>\n",
       "      <td>bappekim</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5843</td>\n",
       "      <td>24</td>\n",
       "      <td>1027</td>\n",
       "      <td>South Korea Visitors</td>\n",
       "      <td>Foreign visitors into South Korea</td>\n",
       "      <td>### Context\\n\\nThis dataset deals with the vis...</td>\n",
       "      <td>False</td>\n",
       "      <td>[global, travel]</td>\n",
       "      <td>[{'name': 'CC-BY-SA-4.0'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hongsean/korea-income-and-welfare</td>\n",
       "      <td>1046735</td>\n",
       "      <td>1046735</td>\n",
       "      <td>korea-income-and-welfare</td>\n",
       "      <td>hongsean</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>3018</td>\n",
       "      <td>15</td>\n",
       "      <td>568</td>\n",
       "      <td>Korea Income and Welfare</td>\n",
       "      <td>Where Korea wealth come from?</td>\n",
       "      <td>![](https://www.googleapis.com/download/storag...</td>\n",
       "      <td>False</td>\n",
       "      <td>[income, education, social issues and advocacy...</td>\n",
       "      <td>[{'name': 'CC0-1.0'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bryanpark/korean-single-speaker-speech-dataset</td>\n",
       "      <td>19829</td>\n",
       "      <td>19829</td>\n",
       "      <td>korean-single-speaker-speech-dataset</td>\n",
       "      <td>bryanpark</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>83396</td>\n",
       "      <td>106</td>\n",
       "      <td>5469</td>\n",
       "      <td>Korean Single Speaker Speech Dataset</td>\n",
       "      <td>KSS Dataset: Korean Single Speaker Speech Dataset</td>\n",
       "      <td># [Updated on September 28, 2019] KSS Dataset:...</td>\n",
       "      <td>False</td>\n",
       "      <td>[languages, arts and entertainment, education]</td>\n",
       "      <td>[{'name': 'CC-BY-NC-SA-4.0'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>llkdev/gender-data</td>\n",
       "      <td>231235</td>\n",
       "      <td>231235</td>\n",
       "      <td>gender-data</td>\n",
       "      <td>llkdev</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Gender Data</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'name': 'unknown'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>chenykfrank/immc21</td>\n",
       "      <td>1135726</td>\n",
       "      <td>1135726</td>\n",
       "      <td>immc21</td>\n",
       "      <td>chenykfrank</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>immc21</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'name': 'unknown'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>anuragshakya2005/gas-prices</td>\n",
       "      <td>981330</td>\n",
       "      <td>981330</td>\n",
       "      <td>gas-prices</td>\n",
       "      <td>anuragshakya2005</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>gas_prices</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'name': 'unknown'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>gremmn/gas-prices</td>\n",
       "      <td>1108372</td>\n",
       "      <td>1108372</td>\n",
       "      <td>gas-prices</td>\n",
       "      <td>gremmn</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>gas prices</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'name': 'unknown'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>theeranartmeesathien/covid-dataset-for-prediction</td>\n",
       "      <td>1392213</td>\n",
       "      <td>1392213</td>\n",
       "      <td>covid-dataset-for-prediction</td>\n",
       "      <td>theeranartmeesathien</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Covid dataset for prediction</td>\n",
       "      <td>Covid-19 related tweets in English</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[social networks]</td>\n",
       "      <td>[{'name': 'unknown'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id    id_no datasetId  \\\n",
       "0                          kimjihoo/coronavirusdataset   527325    527325   \n",
       "1                      bappekim/air-pollution-in-seoul   576393    576393   \n",
       "2                        bappekim/south-korea-visitors   692628    692628   \n",
       "3                    hongsean/korea-income-and-welfare  1046735   1046735   \n",
       "4       bryanpark/korean-single-speaker-speech-dataset    19829     19829   \n",
       "..                                                 ...      ...       ...   \n",
       "169                                 llkdev/gender-data   231235    231235   \n",
       "170                                 chenykfrank/immc21  1135726   1135726   \n",
       "171                        anuragshakya2005/gas-prices   981330    981330   \n",
       "172                                  gremmn/gas-prices  1108372   1108372   \n",
       "173  theeranartmeesathien/covid-dataset-for-prediction  1392213   1392213   \n",
       "\n",
       "                              datasetSlug             ownerUser  \\\n",
       "0                      coronavirusdataset              kimjihoo   \n",
       "1                  air-pollution-in-seoul              bappekim   \n",
       "2                    south-korea-visitors              bappekim   \n",
       "3                korea-income-and-welfare              hongsean   \n",
       "4    korean-single-speaker-speech-dataset             bryanpark   \n",
       "..                                    ...                   ...   \n",
       "169                           gender-data                llkdev   \n",
       "170                                immc21           chenykfrank   \n",
       "171                            gas-prices      anuragshakya2005   \n",
       "172                            gas-prices                gremmn   \n",
       "173          covid-dataset-for-prediction  theeranartmeesathien   \n",
       "\n",
       "     usabilityRating totalViews totalVotes totalDownloads  \\\n",
       "0           1.000000     490936       1465          82997   \n",
       "1           1.000000      81243        309           9741   \n",
       "2           1.000000       5843         24           1027   \n",
       "3           0.970588       3018         15            568   \n",
       "4           0.750000      83396        106           5469   \n",
       "..               ...        ...        ...            ...   \n",
       "169         0.125000        338          0              8   \n",
       "170         0.117647         44          0              0   \n",
       "171         0.117647        208          1             41   \n",
       "172         0.117647        168          0             12   \n",
       "173         0.352941          8          0              0   \n",
       "\n",
       "                                               title  \\\n",
       "0    [NeurIPS 2020] Data Science for COVID-19 (DS4C)   \n",
       "1                             Air Pollution in Seoul   \n",
       "2                               South Korea Visitors   \n",
       "3                           Korea Income and Welfare   \n",
       "4               Korean Single Speaker Speech Dataset   \n",
       "..                                               ...   \n",
       "169                                      Gender Data   \n",
       "170                                           immc21   \n",
       "171                                       gas_prices   \n",
       "172                                       gas prices   \n",
       "173                     Covid dataset for prediction   \n",
       "\n",
       "                                              subtitle  \\\n",
       "0       DS4C: Data Science for COVID-19 in South Korea   \n",
       "1    Air Pollution Measurement Information in Seoul...   \n",
       "2                    Foreign visitors into South Korea   \n",
       "3                        Where Korea wealth come from?   \n",
       "4    KSS Dataset: Korean Single Speaker Speech Dataset   \n",
       "..                                                 ...   \n",
       "169                                                      \n",
       "170                                                      \n",
       "171                                                      \n",
       "172                                                      \n",
       "173                 Covid-19 related tweets in English   \n",
       "\n",
       "                                           description isPrivate  \\\n",
       "0    ### A portion of our dataset has been accepted...     False   \n",
       "1    ### Context\\nThis dataset deals with air pollu...     False   \n",
       "2    ### Context\\n\\nThis dataset deals with the vis...     False   \n",
       "3    ![](https://www.googleapis.com/download/storag...     False   \n",
       "4    # [Updated on September 28, 2019] KSS Dataset:...     False   \n",
       "..                                                 ...       ...   \n",
       "169                                                        False   \n",
       "170                                                        False   \n",
       "171                                                        False   \n",
       "172                                                        False   \n",
       "173                                                        False   \n",
       "\n",
       "                                              keywords  \\\n",
       "0    [universities and colleges, biology, data visu...   \n",
       "1           [earth and nature, environment, pollution]   \n",
       "2                                     [global, travel]   \n",
       "3    [income, education, social issues and advocacy...   \n",
       "4       [languages, arts and entertainment, education]   \n",
       "..                                                 ...   \n",
       "169                                                 []   \n",
       "170                                                 []   \n",
       "171                                                 []   \n",
       "172                                                 []   \n",
       "173                                  [social networks]   \n",
       "\n",
       "                          licenses  \\\n",
       "0    [{'name': 'CC-BY-NC-SA-4.0'}]   \n",
       "1       [{'name': 'CC-BY-SA-4.0'}]   \n",
       "2       [{'name': 'CC-BY-SA-4.0'}]   \n",
       "3            [{'name': 'CC0-1.0'}]   \n",
       "4    [{'name': 'CC-BY-NC-SA-4.0'}]   \n",
       "..                             ...   \n",
       "169          [{'name': 'unknown'}]   \n",
       "170          [{'name': 'unknown'}]   \n",
       "171          [{'name': 'unknown'}]   \n",
       "172          [{'name': 'unknown'}]   \n",
       "173          [{'name': 'unknown'}]   \n",
       "\n",
       "                                         collaborators data  \n",
       "0    [{'username': 'kjm0623v', 'role': 'writer'}, {...   []  \n",
       "1                                                   []   []  \n",
       "2                                                   []   []  \n",
       "3                                                   []   []  \n",
       "4                                                   []   []  \n",
       "..                                                 ...  ...  \n",
       "169                                                 []   []  \n",
       "170                                                 []   []  \n",
       "171                                                 []   []  \n",
       "172                                                 []   []  \n",
       "173                                                 []   []  \n",
       "\n",
       "[174 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
