{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilizes the Kaggle API. Follow these steps in order to get the necessary credentials to continue:\n",
    "\n",
    "1. Sign up for a Kaggle account at https://www.kaggle.com.\n",
    "2. Go to the 'Account' tab of your user profile - ```https://www.kaggle.com/{username}/account```.\n",
    "3. Select 'Create New API Token' under 'API' section.\n",
    "    - This will trigger the download of kaggle.json, a file containing your API credentials. \n",
    "4. Place this file in the location:\n",
    "    - ~/.kaggle/kaggle.json (for macOS/unix)\n",
    "    - C:/Users/username/.kaggle/kaggle.json (for Windows) \n",
    "    - You can check the exact location, sans drive, with echo %HOMEPATH%). \n",
    "    - You can define a shell environment variable KAGGLE_CONFIG_DIR to change this location to:\n",
    "        - $KAGGLE_CONFIG_DIR/kaggle.json (for macOS/unix)\n",
    "        - %KAGGLE_CONFIG_DIR%\\kaggle.json (for Windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this notebook uses functions written in Python to query the Kaggle API. **This code will only work for python 3.7 or later**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation Guide:\n",
    "- Kaggle API ([Kaggle](https://www.kaggle.com/docs/api))\n",
    "- Kaggle API ([GitHub](https://github.com/Kaggle/kaggle-api)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/Kaggle_workflow.jpg\" width=650 height=650 align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Allow system to search parent folder for local imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import kaggle\n",
    "import subprocess # Used to run unix commands\n",
    "import pandas as pd # For storing/manipulating command data\n",
    "from io import StringIO # Lets us read csv string output from command into DataFrame\n",
    "import json # Reading back the metadata files\n",
    "from tqdm import tqdm # Gives status bar on loop completion\n",
    "import itertools # For efficient looping over queries\n",
    "import os # Exporting saved results\n",
    "from collections import OrderedDict\n",
    "from utils import flatten_nested_df\n",
    "from flatten_json import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query #1: query API based on search terms and search types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `get_all_search_outputs` queries the Kaggle API for all combinations of search terms and search types specified and returns the results as a dictionary of dataframes (one dataframe for each query combination)\n",
    "- Calls function `get_individual_search_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_search_outputs(search_terms, search_types, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Call the Kaggle API for each search term and search type. \n",
    "    Results are retured in results['{term}_{type}'] = df\n",
    "    \n",
    "    Params:\n",
    "    - search_terms (list-like): collection of search terms to query over\n",
    "    - search_types (list-like): collection of search types to query over\n",
    "    - flatten_output (bool): optional (default=False)\n",
    "    \n",
    "    Returns:\n",
    "    - results (dict): dictionary consisting of returned DataFrames from get_search_output for each query\n",
    "    \"\"\"\n",
    "    \n",
    "    num_searches = len(search_terms) * len(search_types)\n",
    "    results = OrderedDict()\n",
    "    \n",
    "    for search_term, search_type in itertools.product(search_terms, search_types):\n",
    "        results[(search_term, search_type)] = get_individual_search_output(search_term, search_type, flatten_output)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `get_individual_search_output` queries the Kaggle API with the specified search term (e.g., “machine learning”) and search type (must be either “datasets” or “kernels”)\n",
    "- Searches across all returned pages\n",
    "- Calls function `_convert_string_csv_output_to_dataframe` which converts results from API (strings in semi-structured table) to dataframe format\n",
    "- Result is a dataframe (one dataframe per search term/search type combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_search_output(search_term, search_type, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Calls the Kaggle API with the specified search term and returns the search output results.\n",
    "    \n",
    "    Params:\n",
    "    - search_term (str): keyword to seach for\n",
    "    - search_type (str): objects to search over (must be either datasets or kernels)\n",
    "    - flatten_output (bool): optional (default=False)\n",
    "    \n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): DataFrame containing the output of the search query\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make sure our input is valid\n",
    "    assert isinstance(search_type, str), 'Search term must be a string'\n",
    "    assert search_type in ('datasets', 'kernels'), 'Search can only be conducted over datasets or kernels'\n",
    "    \n",
    "    # Set search variables\n",
    "    page_idx = 1\n",
    "    search_output = ''\n",
    "    cumulative_output = ''\n",
    "    completion_phrase = f'No {search_type} found\\n'\n",
    "    \n",
    "    # Pulls the records for a single page of datasets for the given search term\n",
    "    # Runs the command, captures the output in stdout, reads it from stdout, and decodes it to str from binary\n",
    "    search_output = subprocess.run(['kaggle', search_type, 'list', '-v', \n",
    "                                     '-p', str(page_idx),\n",
    "                                     '-s', search_term], \n",
    "                                    capture_output=True).stdout.decode()\n",
    "\n",
    "    # Once we no longer see new output, we stop\n",
    "    while search_output != completion_phrase:\n",
    "        # Accumulate the output\n",
    "        cumulative_output = cumulative_output + search_output\n",
    "\n",
    "        # Increments the page count for searching\n",
    "        page_idx += 1\n",
    "\n",
    "        # Pulls the records for a single page of datasets for the given search term\n",
    "        # Runs the command, captures the output in stdout, reads it from stdout, and decodes it to str from binary\n",
    "        search_output = subprocess.run(['kaggle', search_type, 'list', '-v',\n",
    "                                         '-p', str(page_idx),\n",
    "                                         '-s', search_term], \n",
    "                                        capture_output=True).stdout.decode()\n",
    "\n",
    "        # Remove header row\n",
    "        if search_output != completion_phrase:\n",
    "            search_output = '\\r\\n'.join(search_output.split('\\r\\n')[1::])\n",
    "    \n",
    "    # Convert search output to DataFrame\n",
    "    search_df = _convert_string_csv_output_to_dataframe(cumulative_output)\n",
    "    \n",
    "    # Rename columns to match names present in metadata df\n",
    "    search_df = search_df.rename(columns={'ref': 'id', \n",
    "                                          'downloadCount': 'totalDownloads', \n",
    "                                          'voteCount': 'totalVotes'}\n",
    "                                )\n",
    "        \n",
    "    if flatten_output:\n",
    "        search_df = flatten_nested_df(search_df)\n",
    "        \n",
    "    # Need to change dtypes for mergin\n",
    "    search_df = search_df.convert_dtypes()\n",
    "    \n",
    "    return search_df.iloc[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `_convert_string_csv_output_to_dataframe` converts raw results from API (strings in semi-structured table) to dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_string_csv_output_to_dataframe(output):\n",
    "    \"\"\"\n",
    "    Given a string variable in csv format, returns a Pandas DataFrame\n",
    "    \n",
    "    Params:\n",
    "    - output (str): csv-styled string to be converted\n",
    "    \n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): DataFrame consisting of data from 'output' string variable\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create DataFrame of results\n",
    "    output = StringIO(output)\n",
    "    df = pd.read_csv(output)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run query #1 functions - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['\"machine learning\"', '\"artificial intelligence\"']\n",
    "search_types = ['datasets', 'kernels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_output_dict = get_all_search_outputs(search_terms, search_types, flatten_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key = (search_terms[0], search_types[0])\n",
    "sample_df = search_output_dict[sample_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>totalDownloads</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kaggle/kaggle-survey-2018</td>\n",
       "      <td>2018 Kaggle Machine Learning &amp; Data Science Su...</td>\n",
       "      <td>4MB</td>\n",
       "      <td>2018-11-03 22:35:07</td>\n",
       "      <td>15381</td>\n",
       "      <td>976</td>\n",
       "      <td>0.85294116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaggle/kaggle-survey-2017</td>\n",
       "      <td>2017 Kaggle Machine Learning &amp; Data Science Su...</td>\n",
       "      <td>4MB</td>\n",
       "      <td>2017-10-27 22:03:03</td>\n",
       "      <td>22997</td>\n",
       "      <td>824</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alopez247/pokemon</td>\n",
       "      <td>Pokémon for Data Mining and Machine Learning</td>\n",
       "      <td>715KB</td>\n",
       "      <td>2017-03-05 15:01:26</td>\n",
       "      <td>10470</td>\n",
       "      <td>241</td>\n",
       "      <td>0.85294116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kashnitsky/mlcourse</td>\n",
       "      <td>mlcourse.ai</td>\n",
       "      <td>51MB</td>\n",
       "      <td>2018-12-09 16:45:09</td>\n",
       "      <td>25404</td>\n",
       "      <td>1376</td>\n",
       "      <td>0.88235295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kaushil268/disease-prediction-using-machine-le...</td>\n",
       "      <td>Disease Prediction Using Machine Learning</td>\n",
       "      <td>30KB</td>\n",
       "      <td>2020-05-15 03:58:44</td>\n",
       "      <td>2413</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>henrysue/online-shoppers-intention</td>\n",
       "      <td>Online Shoppers Intention UCI Machine Learning</td>\n",
       "      <td>252KB</td>\n",
       "      <td>2020-01-15 20:19:02</td>\n",
       "      <td>1224</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shashwatwork/phishing-dataset-for-machine-lear...</td>\n",
       "      <td>Phishing Dataset for Machine Learning</td>\n",
       "      <td>234KB</td>\n",
       "      <td>2021-05-28 14:47:37</td>\n",
       "      <td>302</td>\n",
       "      <td>20</td>\n",
       "      <td>0.9411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rikdifos/credit-card-approval-prediction</td>\n",
       "      <td>Credit Card Approval Prediction</td>\n",
       "      <td>5MB</td>\n",
       "      <td>2020-03-24 10:04:48</td>\n",
       "      <td>15583</td>\n",
       "      <td>319</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cristeaioan/ffml-dataset</td>\n",
       "      <td>Food For Machine Learning</td>\n",
       "      <td>64MB</td>\n",
       "      <td>2020-04-24 09:10:45</td>\n",
       "      <td>723</td>\n",
       "      <td>18</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saxenapriyansh/coursera-machine-learning-andre...</td>\n",
       "      <td>Coursera - Machine Learning - Andrew_Ng</td>\n",
       "      <td>4KB</td>\n",
       "      <td>2018-12-25 12:27:33</td>\n",
       "      <td>423</td>\n",
       "      <td>19</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>brsdincer/vehicle-detection-image-set</td>\n",
       "      <td>Vehicle Detection Image Set</td>\n",
       "      <td>119MB</td>\n",
       "      <td>2021-05-09 17:54:02</td>\n",
       "      <td>667</td>\n",
       "      <td>49</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shuofxz/titanic-machine-learning-from-disaster</td>\n",
       "      <td>Titanic: Machine Learning from Disaster</td>\n",
       "      <td>33KB</td>\n",
       "      <td>2017-10-15 10:05:34</td>\n",
       "      <td>2776</td>\n",
       "      <td>42</td>\n",
       "      <td>0.29411766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vikrishnan/boston-house-prices</td>\n",
       "      <td>Boston House Prices</td>\n",
       "      <td>13KB</td>\n",
       "      <td>2017-08-03 17:06:12</td>\n",
       "      <td>39312</td>\n",
       "      <td>318</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>uciml/zoo-animal-classification</td>\n",
       "      <td>Zoo Animal Classification</td>\n",
       "      <td>2KB</td>\n",
       "      <td>2016-12-24 18:05:10</td>\n",
       "      <td>23396</td>\n",
       "      <td>302</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rahulsah06/machine-learning-for-diabetes-with-...</td>\n",
       "      <td>Machine Learning for Diabetes with Python</td>\n",
       "      <td>9KB</td>\n",
       "      <td>2019-09-20 08:04:12</td>\n",
       "      <td>852</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>oossiiris/hackerearth-machine-learning-exhibit...</td>\n",
       "      <td>HackerEarth Machine Learning  : Exhibit A(rt)</td>\n",
       "      <td>512KB</td>\n",
       "      <td>2021-02-06 07:36:56</td>\n",
       "      <td>103</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gauravsahani/andrewng-machine-learning-tweets</td>\n",
       "      <td>AndrewNg Machine Learning Tweets</td>\n",
       "      <td>124KB</td>\n",
       "      <td>2020-06-06 13:00:45</td>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sarahvch/breast-cancer-wisconsin-prognostic-da...</td>\n",
       "      <td>Breast Cancer Wisconsin (Prognostic) Data Set</td>\n",
       "      <td>49KB</td>\n",
       "      <td>2017-03-31 22:47:50</td>\n",
       "      <td>2519</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mirichoi0218/insurance</td>\n",
       "      <td>Medical Cost Personal Datasets</td>\n",
       "      <td>16KB</td>\n",
       "      <td>2018-02-21 00:15:14</td>\n",
       "      <td>81367</td>\n",
       "      <td>1377</td>\n",
       "      <td>0.88235295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>uciml/mushroom-classification</td>\n",
       "      <td>Mushroom Classification</td>\n",
       "      <td>34KB</td>\n",
       "      <td>2016-12-01 23:08:00</td>\n",
       "      <td>70921</td>\n",
       "      <td>1688</td>\n",
       "      <td>0.85294116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mlg-ulb/creditcardfraud</td>\n",
       "      <td>Credit Card Fraud Detection</td>\n",
       "      <td>66MB</td>\n",
       "      <td>2018-03-23 01:17:27</td>\n",
       "      <td>337510</td>\n",
       "      <td>8144</td>\n",
       "      <td>0.85294116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tentotheminus9/seti-data</td>\n",
       "      <td>SETI Data</td>\n",
       "      <td>5GB</td>\n",
       "      <td>2018-09-28 10:18:06</td>\n",
       "      <td>695</td>\n",
       "      <td>88</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>neelima98/disease-prediction-using-machine-lea...</td>\n",
       "      <td>DISEASE PREDICTION USING MACHINE LEARNING WITH...</td>\n",
       "      <td>30KB</td>\n",
       "      <td>2019-04-03 04:50:17</td>\n",
       "      <td>3090</td>\n",
       "      <td>54</td>\n",
       "      <td>0.5294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>karthickveerakumar/salary-data-simple-linear-r...</td>\n",
       "      <td>Salary data - Simple linear regression</td>\n",
       "      <td>378B</td>\n",
       "      <td>2018-01-22 17:09:38</td>\n",
       "      <td>17631</td>\n",
       "      <td>152</td>\n",
       "      <td>0.3529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>camnugent/california-housing-prices</td>\n",
       "      <td>California Housing Prices</td>\n",
       "      <td>400KB</td>\n",
       "      <td>2017-11-24 03:14:59</td>\n",
       "      <td>41953</td>\n",
       "      <td>518</td>\n",
       "      <td>0.85294116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>eiodelami/disease-outbreaks-in-nigeria-datasets</td>\n",
       "      <td>Disease Outbreaks in Nigeria Datasets</td>\n",
       "      <td>8MB</td>\n",
       "      <td>2019-05-02 23:33:23</td>\n",
       "      <td>1283</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>vinesmsuic/star-categorization-giants-and-dwarfs</td>\n",
       "      <td>Star Dataset: Stellar Classification [Beginner]</td>\n",
       "      <td>2MB</td>\n",
       "      <td>2020-08-21 14:10:42</td>\n",
       "      <td>794</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rahulsah06/titanic</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>34KB</td>\n",
       "      <td>2019-09-16 14:43:23</td>\n",
       "      <td>2035</td>\n",
       "      <td>33</td>\n",
       "      <td>0.6764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>abcsds/pokemon</td>\n",
       "      <td>Pokemon with stats</td>\n",
       "      <td>15KB</td>\n",
       "      <td>2016-08-29 06:01:43</td>\n",
       "      <td>70110</td>\n",
       "      <td>1935</td>\n",
       "      <td>0.88235295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>vaghefi/indeed-jobs</td>\n",
       "      <td>Machine Learning Jobs</td>\n",
       "      <td>4MB</td>\n",
       "      <td>2020-08-28 06:56:49</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>baiazid/coursera-machine-learning-su-ex1</td>\n",
       "      <td>Coursera - Machine Learning - SU</td>\n",
       "      <td>4KB</td>\n",
       "      <td>2017-09-25 11:03:12</td>\n",
       "      <td>546</td>\n",
       "      <td>7</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>vjchoudhary7/customer-segmentation-tutorial-in...</td>\n",
       "      <td>Mall Customer Segmentation Data</td>\n",
       "      <td>2KB</td>\n",
       "      <td>2018-08-11 07:23:02</td>\n",
       "      <td>67950</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.88235295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>inIT-OWL/genesis-demonstrator-data-for-machine...</td>\n",
       "      <td>Genesis demonstrator data for machine learning</td>\n",
       "      <td>574KB</td>\n",
       "      <td>2018-07-23 14:55:44</td>\n",
       "      <td>772</td>\n",
       "      <td>28</td>\n",
       "      <td>0.88235295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>elakiricoder/gender-classification-dataset</td>\n",
       "      <td>Gender Classification Dataset</td>\n",
       "      <td>19KB</td>\n",
       "      <td>2020-10-06 02:44:12</td>\n",
       "      <td>959</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>burakhmmtgl/predict-molecular-properties</td>\n",
       "      <td>Predict Molecular Properties</td>\n",
       "      <td>91MB</td>\n",
       "      <td>2017-08-14 19:35:25</td>\n",
       "      <td>971</td>\n",
       "      <td>75</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>andrewmvd/heart-failure-clinical-data</td>\n",
       "      <td>Heart Failure Prediction</td>\n",
       "      <td>4KB</td>\n",
       "      <td>2020-06-20 01:03:20</td>\n",
       "      <td>52449</td>\n",
       "      <td>1235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>rudymizrahi/airbnb-listings-in-major-us-cities...</td>\n",
       "      <td>AirBnB listings in major US cities</td>\n",
       "      <td>42MB</td>\n",
       "      <td>2018-03-14 22:02:26</td>\n",
       "      <td>3108</td>\n",
       "      <td>54</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>noahgift/social-power-nba</td>\n",
       "      <td>Social Power NBA</td>\n",
       "      <td>1MB</td>\n",
       "      <td>2017-08-01 02:39:55</td>\n",
       "      <td>8424</td>\n",
       "      <td>171</td>\n",
       "      <td>0.85294116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gdaley/hkracing</td>\n",
       "      <td>Horse Racing in HK</td>\n",
       "      <td>3MB</td>\n",
       "      <td>2019-11-17 22:23:27</td>\n",
       "      <td>4216</td>\n",
       "      <td>89</td>\n",
       "      <td>0.7647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>walacedatasci/hands-on-machine-learning-housin...</td>\n",
       "      <td>Hands on Machine Learning Book - Housing Dataset</td>\n",
       "      <td>400KB</td>\n",
       "      <td>2019-03-13 00:13:00</td>\n",
       "      <td>906</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>energykingdom/saudi-arabia-car-prices-machine-...</td>\n",
       "      <td>Saudi Arabia car prices Machine Learning.</td>\n",
       "      <td>1KB</td>\n",
       "      <td>2019-08-25 17:41:21</td>\n",
       "      <td>403</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>carrie1/ecommerce-data</td>\n",
       "      <td>E-Commerce Data</td>\n",
       "      <td>7MB</td>\n",
       "      <td>2017-08-17 02:44:30</td>\n",
       "      <td>65223</td>\n",
       "      <td>1045</td>\n",
       "      <td>0.7058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>nehalbirla/vehicle-dataset-from-cardekho</td>\n",
       "      <td>Vehicle dataset</td>\n",
       "      <td>227KB</td>\n",
       "      <td>2020-10-24 01:29:16</td>\n",
       "      <td>35849</td>\n",
       "      <td>407</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ryleymcconkey/ml-turbulence-dataset</td>\n",
       "      <td>Turbulence modelling using machine learning</td>\n",
       "      <td>5GB</td>\n",
       "      <td>2021-03-21 13:33:24</td>\n",
       "      <td>172</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>shravankoninti/av-janatahack-machine-learning-...</td>\n",
       "      <td>AV JanataHack: Machine Learning in Agriculture</td>\n",
       "      <td>1MB</td>\n",
       "      <td>2020-07-24 19:20:58</td>\n",
       "      <td>205</td>\n",
       "      <td>9</td>\n",
       "      <td>0.47058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>antonyj453/urldataset</td>\n",
       "      <td>Malicious_n_Non-Malicious URL</td>\n",
       "      <td>7MB</td>\n",
       "      <td>2017-11-27 12:15:17</td>\n",
       "      <td>2004</td>\n",
       "      <td>31</td>\n",
       "      <td>0.47058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>krantiswalke/bank-personal-loan-modelling</td>\n",
       "      <td>Bank_Personal_Loan_Modelling</td>\n",
       "      <td>61KB</td>\n",
       "      <td>2020-04-17 17:02:39</td>\n",
       "      <td>847</td>\n",
       "      <td>19</td>\n",
       "      <td>0.64705884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>gabrielegalimberti/movies-example-for-machine-...</td>\n",
       "      <td>Movies example for machine learning activities</td>\n",
       "      <td>123KB</td>\n",
       "      <td>2019-03-04 11:51:58</td>\n",
       "      <td>481</td>\n",
       "      <td>12</td>\n",
       "      <td>0.88235295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>schirmerchad/bostonhoustingmlnd</td>\n",
       "      <td>Boston Housing</td>\n",
       "      <td>4KB</td>\n",
       "      <td>2017-06-11 15:07:11</td>\n",
       "      <td>11724</td>\n",
       "      <td>140</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>clmentbisaillon/fake-and-real-news-dataset</td>\n",
       "      <td>Fake and real news dataset</td>\n",
       "      <td>41MB</td>\n",
       "      <td>2020-03-26 18:51:15</td>\n",
       "      <td>34503</td>\n",
       "      <td>1073</td>\n",
       "      <td>0.88235295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   id  \\\n",
       "0                           kaggle/kaggle-survey-2018   \n",
       "1                           kaggle/kaggle-survey-2017   \n",
       "2                                   alopez247/pokemon   \n",
       "3                                 kashnitsky/mlcourse   \n",
       "4   kaushil268/disease-prediction-using-machine-le...   \n",
       "5                  henrysue/online-shoppers-intention   \n",
       "6   shashwatwork/phishing-dataset-for-machine-lear...   \n",
       "7            rikdifos/credit-card-approval-prediction   \n",
       "8                            cristeaioan/ffml-dataset   \n",
       "9   saxenapriyansh/coursera-machine-learning-andre...   \n",
       "10              brsdincer/vehicle-detection-image-set   \n",
       "11     shuofxz/titanic-machine-learning-from-disaster   \n",
       "12                     vikrishnan/boston-house-prices   \n",
       "13                    uciml/zoo-animal-classification   \n",
       "14  rahulsah06/machine-learning-for-diabetes-with-...   \n",
       "15  oossiiris/hackerearth-machine-learning-exhibit...   \n",
       "16      gauravsahani/andrewng-machine-learning-tweets   \n",
       "17  sarahvch/breast-cancer-wisconsin-prognostic-da...   \n",
       "18                             mirichoi0218/insurance   \n",
       "19                      uciml/mushroom-classification   \n",
       "20                            mlg-ulb/creditcardfraud   \n",
       "21                           tentotheminus9/seti-data   \n",
       "22  neelima98/disease-prediction-using-machine-lea...   \n",
       "23  karthickveerakumar/salary-data-simple-linear-r...   \n",
       "24                camnugent/california-housing-prices   \n",
       "25    eiodelami/disease-outbreaks-in-nigeria-datasets   \n",
       "26   vinesmsuic/star-categorization-giants-and-dwarfs   \n",
       "27                                 rahulsah06/titanic   \n",
       "28                                     abcsds/pokemon   \n",
       "29                                vaghefi/indeed-jobs   \n",
       "30           baiazid/coursera-machine-learning-su-ex1   \n",
       "31  vjchoudhary7/customer-segmentation-tutorial-in...   \n",
       "32  inIT-OWL/genesis-demonstrator-data-for-machine...   \n",
       "33         elakiricoder/gender-classification-dataset   \n",
       "34           burakhmmtgl/predict-molecular-properties   \n",
       "35              andrewmvd/heart-failure-clinical-data   \n",
       "36  rudymizrahi/airbnb-listings-in-major-us-cities...   \n",
       "37                          noahgift/social-power-nba   \n",
       "38                                    gdaley/hkracing   \n",
       "39  walacedatasci/hands-on-machine-learning-housin...   \n",
       "40  energykingdom/saudi-arabia-car-prices-machine-...   \n",
       "41                             carrie1/ecommerce-data   \n",
       "42           nehalbirla/vehicle-dataset-from-cardekho   \n",
       "43                ryleymcconkey/ml-turbulence-dataset   \n",
       "44  shravankoninti/av-janatahack-machine-learning-...   \n",
       "45                              antonyj453/urldataset   \n",
       "46          krantiswalke/bank-personal-loan-modelling   \n",
       "47  gabrielegalimberti/movies-example-for-machine-...   \n",
       "48                    schirmerchad/bostonhoustingmlnd   \n",
       "49         clmentbisaillon/fake-and-real-news-dataset   \n",
       "\n",
       "                                                title   size  \\\n",
       "0   2018 Kaggle Machine Learning & Data Science Su...    4MB   \n",
       "1   2017 Kaggle Machine Learning & Data Science Su...    4MB   \n",
       "2        Pokémon for Data Mining and Machine Learning  715KB   \n",
       "3                                         mlcourse.ai   51MB   \n",
       "4          Disease Prediction Using Machine Learning    30KB   \n",
       "5      Online Shoppers Intention UCI Machine Learning  252KB   \n",
       "6               Phishing Dataset for Machine Learning  234KB   \n",
       "7                     Credit Card Approval Prediction    5MB   \n",
       "8                           Food For Machine Learning   64MB   \n",
       "9             Coursera - Machine Learning - Andrew_Ng    4KB   \n",
       "10                        Vehicle Detection Image Set  119MB   \n",
       "11            Titanic: Machine Learning from Disaster   33KB   \n",
       "12                                Boston House Prices   13KB   \n",
       "13                          Zoo Animal Classification    2KB   \n",
       "14          Machine Learning for Diabetes with Python    9KB   \n",
       "15      HackerEarth Machine Learning  : Exhibit A(rt)  512KB   \n",
       "16                   AndrewNg Machine Learning Tweets  124KB   \n",
       "17      Breast Cancer Wisconsin (Prognostic) Data Set   49KB   \n",
       "18                     Medical Cost Personal Datasets   16KB   \n",
       "19                            Mushroom Classification   34KB   \n",
       "20                        Credit Card Fraud Detection   66MB   \n",
       "21                                          SETI Data    5GB   \n",
       "22  DISEASE PREDICTION USING MACHINE LEARNING WITH...   30KB   \n",
       "23             Salary data - Simple linear regression   378B   \n",
       "24                          California Housing Prices  400KB   \n",
       "25              Disease Outbreaks in Nigeria Datasets    8MB   \n",
       "26    Star Dataset: Stellar Classification [Beginner]    2MB   \n",
       "27                                           Titanic    34KB   \n",
       "28                                 Pokemon with stats   15KB   \n",
       "29                              Machine Learning Jobs    4MB   \n",
       "30                   Coursera - Machine Learning - SU    4KB   \n",
       "31                    Mall Customer Segmentation Data    2KB   \n",
       "32     Genesis demonstrator data for machine learning  574KB   \n",
       "33                      Gender Classification Dataset   19KB   \n",
       "34                       Predict Molecular Properties   91MB   \n",
       "35                           Heart Failure Prediction    4KB   \n",
       "36                 AirBnB listings in major US cities   42MB   \n",
       "37                                   Social Power NBA    1MB   \n",
       "38                                 Horse Racing in HK    3MB   \n",
       "39   Hands on Machine Learning Book - Housing Dataset  400KB   \n",
       "40          Saudi Arabia car prices Machine Learning.    1KB   \n",
       "41                                    E-Commerce Data    7MB   \n",
       "42                                    Vehicle dataset  227KB   \n",
       "43        Turbulence modelling using machine learning    5GB   \n",
       "44     AV JanataHack: Machine Learning in Agriculture    1MB   \n",
       "45                      Malicious_n_Non-Malicious URL    7MB   \n",
       "46                       Bank_Personal_Loan_Modelling   61KB   \n",
       "47     Movies example for machine learning activities  123KB   \n",
       "48                                     Boston Housing    4KB   \n",
       "49                         Fake and real news dataset   41MB   \n",
       "\n",
       "            lastUpdated  totalDownloads  totalVotes usabilityRating  \n",
       "0   2018-11-03 22:35:07           15381         976      0.85294116  \n",
       "1   2017-10-27 22:03:03           22997         824       0.8235294  \n",
       "2   2017-03-05 15:01:26           10470         241      0.85294116  \n",
       "3   2018-12-09 16:45:09           25404        1376      0.88235295  \n",
       "4   2020-05-15 03:58:44            2413          42       0.8235294  \n",
       "5   2020-01-15 20:19:02            1224          33             1.0  \n",
       "6   2021-05-28 14:47:37             302          20       0.9411765  \n",
       "7   2020-03-24 10:04:48           15583         319             1.0  \n",
       "8   2020-04-24 09:10:45             723          18          0.8125  \n",
       "9   2018-12-25 12:27:33             423          19           0.875  \n",
       "10  2021-05-09 17:54:02             667          49           0.875  \n",
       "11  2017-10-15 10:05:34            2776          42      0.29411766  \n",
       "12  2017-08-03 17:06:12           39312         318       0.8235294  \n",
       "13  2016-12-24 18:05:10           23396         302       0.8235294  \n",
       "14  2019-09-20 08:04:12             852          20       0.5882353  \n",
       "15  2021-02-06 07:36:56             103          12       0.7058824  \n",
       "16  2020-06-06 13:00:45              48          14       0.7058824  \n",
       "17  2017-03-31 22:47:50            2519          42       0.8235294  \n",
       "18  2018-02-21 00:15:14           81367        1377      0.88235295  \n",
       "19  2016-12-01 23:08:00           70921        1688      0.85294116  \n",
       "20  2018-03-23 01:17:27          337510        8144      0.85294116  \n",
       "21  2018-09-28 10:18:06             695          88           0.625  \n",
       "22  2019-04-03 04:50:17            3090          54       0.5294118  \n",
       "23  2018-01-22 17:09:38           17631         152       0.3529412  \n",
       "24  2017-11-24 03:14:59           41953         518      0.85294116  \n",
       "25  2019-05-02 23:33:23            1283          41       0.9411765  \n",
       "26  2020-08-21 14:10:42             794          30             1.0  \n",
       "27  2019-09-16 14:43:23            2035          33       0.6764706  \n",
       "28  2016-08-29 06:01:43           70110        1935      0.88235295  \n",
       "29  2020-08-28 06:56:49              79           6             1.0  \n",
       "30  2017-09-25 11:03:12             546           7          0.4375  \n",
       "31  2018-08-11 07:23:02           67950        1115      0.88235295  \n",
       "32  2018-07-23 14:55:44             772          28      0.88235295  \n",
       "33  2020-10-06 02:44:12             959          22             1.0  \n",
       "34  2017-08-14 19:35:25             971          75           0.875  \n",
       "35  2020-06-20 01:03:20           52449        1235             1.0  \n",
       "36  2018-03-14 22:02:26            3108          54       0.8235294  \n",
       "37  2017-08-01 02:39:55            8424         171      0.85294116  \n",
       "38  2019-11-17 22:23:27            4216          89       0.7647059  \n",
       "39  2019-03-13 00:13:00             906           9       0.7058824  \n",
       "40  2019-08-25 17:41:21             403          13       0.7647059  \n",
       "41  2017-08-17 02:44:30           65223        1045       0.7058824  \n",
       "42  2020-10-24 01:29:16           35849         407             1.0  \n",
       "43  2021-03-21 13:33:24             172          10          0.8125  \n",
       "44  2020-07-24 19:20:58             205           9      0.47058824  \n",
       "45  2017-11-27 12:15:17            2004          31      0.47058824  \n",
       "46  2020-04-17 17:02:39             847          19      0.64705884  \n",
       "47  2019-03-04 11:51:58             481          12      0.88235295  \n",
       "48  2017-06-11 15:07:11           11724         140       0.8235294  \n",
       "49  2020-03-26 18:51:15           34503        1073      0.88235295  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query #2: query API for full metadata for hits from initial query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Unable to find a way to store metadata in memory as opposed to saving file, but this workaround appears to be functional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `_retrieve_object_json` uses the path for each object (each dataframe in result #1 ordered dictionary to query API for metadata associated with each object. Loads JSON results as dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _retrieve_object_json(object_path, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Queries Kaggle for metadata json file & returns the json data as a dictionary\n",
    "    \n",
    "    Params:\n",
    "    - object_path (str): path for the dataset\n",
    "    - flatten_output (bool): optional (default=False)\n",
    "    \n",
    "    Returns:\n",
    "    - metadata_dict (dict): dictionary containing json metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    # Download the metadata\n",
    "    process = subprocess.run(['kaggle', 'datasets', 'metadata', object_path])\n",
    "    \n",
    "    # If the query did not return metadata\n",
    "    if process.returncode == 1:\n",
    "        return None\n",
    "    else:\n",
    "        # Access the metadata and load it in as a dictionary\n",
    "        with open('dataset-metadata.json') as file:\n",
    "            json_data = json.load(file)\n",
    "\n",
    "        if flatten_output:\n",
    "            json_data = flatten(json_data)\n",
    "\n",
    "        return json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `get_query_metadata` extracts metadata associated with each object and formats as dataframe\n",
    "- Calls function `_retrieve_object_json`\n",
    "- For each object, appends JSON results from `_retrieve_object_json` to a dataframe (converting to dataframe format)\n",
    "- Output is single dataframe for each search query (matching each dataframe in result #1 ordered dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_metadata(object_paths, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Retrieves the metadata for the file/files listed in object_paths\n",
    "    \n",
    "    Params:\n",
    "    - object_paths (str/list-like): string or list of strings containing the paths for the objects\n",
    "    - flatten_output (bool): optional (default=False)\n",
    "    \n",
    "    Returns:\n",
    "    - metadata_df (pandas.DataFrame): DataFrame containing metadata for the requested datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    # If a singular search term is provided as a string, need to wrap it in a list\n",
    "    if type(object_paths) == str:\n",
    "        object_paths = [object_paths]\n",
    "    \n",
    "    # Make sure our input is valid\n",
    "    assert len(object_paths) > 0, 'Please enter at least one object id'\n",
    "        \n",
    "    # Run first query\n",
    "    json_data = _retrieve_object_json(object_paths[0], flatten_output)\n",
    "        \n",
    "    # Create DataFrame to store metadata in, using columns found in first query, and then add query info\n",
    "    metadata_df = pd.DataFrame(json_data)\n",
    "        \n",
    "    # Pulls metadata information for each dataset found above\n",
    "    for object_path in tqdm(object_paths[1:50:]):\n",
    "        # Download & load the metadata\n",
    "        json_data = _retrieve_object_json(object_path, flatten_output)\n",
    "\n",
    "        # Store the metadata into our DataFrame created above\n",
    "        metadata_df = metadata_df.append(json_data, ignore_index=True)\n",
    "        \n",
    "    # Convert datatypes (for some reason totalDownloads and totalViews are floats)\n",
    "    metadata_df = metadata_df.convert_dtypes()\n",
    "        \n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `get_all_metadata` uses a `for` loop to put dataframes into an ordered dictionary, matching result #1 ordered dictionary\n",
    "- Calls function `get_query_metadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_all_metadata(search_output_dict, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Retrieves all of the metadata that relates to the provided DataFrames\n",
    "    \n",
    "    Params:\n",
    "    - search_output_dict : dict\n",
    "        Dictionary of DataFrames from get_all_search_outputs\n",
    "    - flatten_output : bool, optional (default=False)\n",
    "        flag for flattening nested columns of output  \n",
    "      \n",
    "    Returns:\n",
    "    - metadata_dict : collections.OrderedDict\n",
    "        OrderedDict of DataFrames with metadata for each query\n",
    "        Order matches the order of search_output_dict\n",
    "    \"\"\"\n",
    "\n",
    "    ## Extract IDs from DataFrame, and returns as list of strings\n",
    "    metadata_dict = OrderedDict()\n",
    "\n",
    "    for query, df in search_output_dict.items():\n",
    "        # Kernels do not have metadata\n",
    "        if 'kernels' not in query:\n",
    "            print(f'Retrieving {query} metadata')\n",
    "            # Create object paths\n",
    "            _, search_type = query\n",
    "            object_paths = df.id.values\n",
    "\n",
    "            metadata_dict[query] = get_query_metadata(object_paths, flatten_output)\n",
    "        \n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving ('\"machine learning\"', 'datasets') metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving ('\"artificial intelligence\"', 'datasets') metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:59<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "metadata_dict = get_all_metadata(search_output_dict, flatten_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine results of query #1 and query #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `merge_search_and_metadata_dicts` merges the output dictionaries from query #1 and query #2 to a single ordered dictionary and (optional) saves the results as a single csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_search_and_metadata_dicts(search_dict, metadata_dict, on=None, left_on=None, right_on=None, save=False):\n",
    "    \"\"\"\n",
    "    Merges together all of the search and metadata DataFrames by the given 'on' key\n",
    "    \n",
    "    Params:\n",
    "    - search_dict (dict): dictionary of search output results\n",
    "    - metadata_dict (dict): dictionary of metadata results\n",
    "    - on (str/list-like): column name(s) to merge the two dicts on\n",
    "    - left_on (str/list-like): column name(s) to merge the left dict on\n",
    "    - right_on (str/list-like): column name(s) to merge the right dict on\n",
    "    - save=False, optional (bool/list-like): specifies if the output DataFrames should be saved\n",
    "        If True: saves to file of format 'data/kaggle/kaggle_{search_term}_{search_type}.csv'\n",
    "        If list-like: saves to respective location in list of save locations\n",
    "            Must contain enough strings (one per query; len(search_terms) * len(search_types))\n",
    "            \n",
    "    Returns:\n",
    "    - df_dict (OrderedDict): OrderedDict containing all of the merged search/metadata dicts\n",
    "    \"\"\"\n",
    "    \n",
    "    num_dataframes = len(search_dict)\n",
    "    \n",
    "    # Ensure the save variable data is proper\n",
    "    try:\n",
    "        if isinstance(save, bool):\n",
    "            save = [save] * num_dataframes\n",
    "        assert len(save) == num_dataframes\n",
    "    except:\n",
    "        raise ValueError('Incorrect save value(s)')\n",
    "\n",
    "    # Merge the DataFrames\n",
    "    df_dict = OrderedDict()\n",
    "    for query_key, save_loc in zip(search_dict.keys(), save):\n",
    "        search_df = search_dict[query_key]\n",
    "        if query_key in metadata_dict:\n",
    "            # Merge small version of \"full\" dataframe with \"detailed\" dataframe\n",
    "            metadata_df = metadata_dict[query_key]\n",
    "            df_all = pd.merge(search_df, metadata_df, on=on, left_on=left_on, right_on=right_on, how='outer')\n",
    "        else:\n",
    "            df_all = search_df\n",
    "        \n",
    "        # Save DataFrame\n",
    "        if save_loc:\n",
    "            data_dir = os.path.join('data', 'kaggle')\n",
    "            if isinstance(save_loc, str):\n",
    "                output_file = save_loc\n",
    "            elif isinstance(save_loc, bool):\n",
    "                # Ensure kaggle directory is already created\n",
    "                if not os.path.isdir(data_dir):\n",
    "                    os.path.mkdir(data_dir)\n",
    "                \n",
    "                search_term, search_type = query_key\n",
    "                output_file = f'{search_term}_{search_type}.csv'\n",
    "            else:\n",
    "                raise ValueError('Save type must be bool or str')\n",
    "\n",
    "            search_df.to_csv(os.path.join(data_dir, output_file), index=False)\n",
    "        \n",
    "        df_dict[query_key] = df_all\n",
    "    \n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run merge function\n",
    "df_dict = merge_search_and_metadata_dicts(search_output_dict, metadata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>totalDownloads</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>usabilityRating</th>\n",
       "      <th>collaborators</th>\n",
       "      <th>data</th>\n",
       "      <th>datasetId</th>\n",
       "      <th>...</th>\n",
       "      <th>ownerUser</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>totalViews</th>\n",
       "      <th>keywords_6</th>\n",
       "      <th>keywords_7</th>\n",
       "      <th>collaborators_0_role</th>\n",
       "      <th>collaborators_0_username</th>\n",
       "      <th>keywords</th>\n",
       "      <th>collaborators_1_role</th>\n",
       "      <th>collaborators_1_username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kaggle/kaggle-survey-2018</td>\n",
       "      <td>2018 Kaggle Machine Learning &amp; Data Science Su...</td>\n",
       "      <td>4MB</td>\n",
       "      <td>2018-11-03 22:35:07</td>\n",
       "      <td>15381</td>\n",
       "      <td>976</td>\n",
       "      <td>0.85294116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaggle/kaggle-survey-2017</td>\n",
       "      <td>2017 Kaggle Machine Learning &amp; Data Science Su...</td>\n",
       "      <td>4MB</td>\n",
       "      <td>2017-10-27 22:03:03</td>\n",
       "      <td>22997</td>\n",
       "      <td>824</td>\n",
       "      <td>0.8235294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alopez247/pokemon</td>\n",
       "      <td>Pokémon for Data Mining and Machine Learning</td>\n",
       "      <td>715KB</td>\n",
       "      <td>2017-03-05 15:01:26</td>\n",
       "      <td>10470</td>\n",
       "      <td>241</td>\n",
       "      <td>0.85294116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kashnitsky/mlcourse</td>\n",
       "      <td>mlcourse.ai</td>\n",
       "      <td>51MB</td>\n",
       "      <td>2018-12-09 16:45:09</td>\n",
       "      <td>25404</td>\n",
       "      <td>1376</td>\n",
       "      <td>0.88235295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kaushil268/disease-prediction-using-machine-le...</td>\n",
       "      <td>Disease Prediction Using Machine Learning</td>\n",
       "      <td>30KB</td>\n",
       "      <td>2020-05-15 03:58:44</td>\n",
       "      <td>2413</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8235294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>antonyj453/urldataset</td>\n",
       "      <td>Malicious_n_Non-Malicious URL</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2004</td>\n",
       "      <td>31</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5423</td>\n",
       "      <td>...</td>\n",
       "      <td>antonyj453</td>\n",
       "      <td>Supervised Machine Learning</td>\n",
       "      <td>14371</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>krantiswalke/bank-personal-loan-modelling</td>\n",
       "      <td>Bank_Personal_Loan_Modelling</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>847</td>\n",
       "      <td>19</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>608073</td>\n",
       "      <td>...</td>\n",
       "      <td>krantiswalke</td>\n",
       "      <td>Bank_Personal_Loan_Modelling_(Machine Learning...</td>\n",
       "      <td>6585</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>svm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>gabrielegalimberti/movies-example-for-machine-...</td>\n",
       "      <td>Movies example for machine learning activities</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>481</td>\n",
       "      <td>12</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>131297</td>\n",
       "      <td>...</td>\n",
       "      <td>gabrielegalimberti</td>\n",
       "      <td>dataset obtain from other datasets of film wit...</td>\n",
       "      <td>4496</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>schirmerchad/bostonhoustingmlnd</td>\n",
       "      <td>Boston Housing</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>11724</td>\n",
       "      <td>140</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1379</td>\n",
       "      <td>...</td>\n",
       "      <td>schirmerchad</td>\n",
       "      <td>Concerns housing values in suburbs of Boston</td>\n",
       "      <td>69885</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>clmentbisaillon/fake-and-real-news-dataset</td>\n",
       "      <td>Fake and real news dataset</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>34503</td>\n",
       "      <td>1073</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>572515</td>\n",
       "      <td>...</td>\n",
       "      <td>clmentbisaillon</td>\n",
       "      <td>Classifying the news</td>\n",
       "      <td>278943</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   id  \\\n",
       "0                           kaggle/kaggle-survey-2018   \n",
       "1                           kaggle/kaggle-survey-2017   \n",
       "2                                   alopez247/pokemon   \n",
       "3                                 kashnitsky/mlcourse   \n",
       "4   kaushil268/disease-prediction-using-machine-le...   \n",
       "..                                                ...   \n",
       "89                              antonyj453/urldataset   \n",
       "90          krantiswalke/bank-personal-loan-modelling   \n",
       "91  gabrielegalimberti/movies-example-for-machine-...   \n",
       "92                    schirmerchad/bostonhoustingmlnd   \n",
       "93         clmentbisaillon/fake-and-real-news-dataset   \n",
       "\n",
       "                                                title   size  \\\n",
       "0   2018 Kaggle Machine Learning & Data Science Su...    4MB   \n",
       "1   2017 Kaggle Machine Learning & Data Science Su...    4MB   \n",
       "2        Pokémon for Data Mining and Machine Learning  715KB   \n",
       "3                                         mlcourse.ai   51MB   \n",
       "4          Disease Prediction Using Machine Learning    30KB   \n",
       "..                                                ...    ...   \n",
       "89                      Malicious_n_Non-Malicious URL   <NA>   \n",
       "90                       Bank_Personal_Loan_Modelling   <NA>   \n",
       "91     Movies example for machine learning activities   <NA>   \n",
       "92                                     Boston Housing   <NA>   \n",
       "93                         Fake and real news dataset   <NA>   \n",
       "\n",
       "            lastUpdated  totalDownloads  totalVotes usabilityRating  \\\n",
       "0   2018-11-03 22:35:07           15381         976      0.85294116   \n",
       "1   2017-10-27 22:03:03           22997         824       0.8235294   \n",
       "2   2017-03-05 15:01:26           10470         241      0.85294116   \n",
       "3   2018-12-09 16:45:09           25404        1376      0.88235295   \n",
       "4   2020-05-15 03:58:44            2413          42       0.8235294   \n",
       "..                  ...             ...         ...             ...   \n",
       "89                 <NA>            2004          31        0.470588   \n",
       "90                 <NA>             847          19        0.647059   \n",
       "91                 <NA>             481          12        0.882353   \n",
       "92                 <NA>           11724         140        0.823529   \n",
       "93                 <NA>           34503        1073        0.882353   \n",
       "\n",
       "   collaborators data  datasetId  ...           ownerUser  \\\n",
       "0            NaN  NaN       <NA>  ...                <NA>   \n",
       "1            NaN  NaN       <NA>  ...                <NA>   \n",
       "2            NaN  NaN       <NA>  ...                <NA>   \n",
       "3            NaN  NaN       <NA>  ...                <NA>   \n",
       "4            NaN  NaN       <NA>  ...                <NA>   \n",
       "..           ...  ...        ...  ...                 ...   \n",
       "89            []   []       5423  ...          antonyj453   \n",
       "90            []   []     608073  ...        krantiswalke   \n",
       "91            []   []     131297  ...  gabrielegalimberti   \n",
       "92            []   []       1379  ...        schirmerchad   \n",
       "93            []   []     572515  ...     clmentbisaillon   \n",
       "\n",
       "                                             subtitle  totalViews  \\\n",
       "0                                                <NA>        <NA>   \n",
       "1                                                <NA>        <NA>   \n",
       "2                                                <NA>        <NA>   \n",
       "3                                                <NA>        <NA>   \n",
       "4                                                <NA>        <NA>   \n",
       "..                                                ...         ...   \n",
       "89                        Supervised Machine Learning       14371   \n",
       "90  Bank_Personal_Loan_Modelling_(Machine Learning...        6585   \n",
       "91  dataset obtain from other datasets of film wit...        4496   \n",
       "92       Concerns housing values in suburbs of Boston       69885   \n",
       "93                               Classifying the news      278943   \n",
       "\n",
       "     keywords_6 keywords_7 collaborators_0_role collaborators_0_username  \\\n",
       "0          <NA>       <NA>                 <NA>                     <NA>   \n",
       "1          <NA>       <NA>                 <NA>                     <NA>   \n",
       "2          <NA>       <NA>                 <NA>                     <NA>   \n",
       "3          <NA>       <NA>                 <NA>                     <NA>   \n",
       "4          <NA>       <NA>                 <NA>                     <NA>   \n",
       "..          ...        ...                  ...                      ...   \n",
       "89         <NA>       <NA>                 <NA>                     <NA>   \n",
       "90  naive bayes        svm                 <NA>                     <NA>   \n",
       "91         <NA>       <NA>                 <NA>                     <NA>   \n",
       "92         <NA>       <NA>                 <NA>                     <NA>   \n",
       "93         <NA>       <NA>                 <NA>                     <NA>   \n",
       "\n",
       "   keywords collaborators_1_role collaborators_1_username  \n",
       "0       NaN                 <NA>                     <NA>  \n",
       "1       NaN                 <NA>                     <NA>  \n",
       "2       NaN                 <NA>                     <NA>  \n",
       "3       NaN                 <NA>                     <NA>  \n",
       "4       NaN                 <NA>                     <NA>  \n",
       "..      ...                  ...                      ...  \n",
       "89      NaN                 <NA>                     <NA>  \n",
       "90      NaN                 <NA>                     <NA>  \n",
       "91      NaN                 <NA>                     <NA>  \n",
       "92      NaN                 <NA>                     <NA>  \n",
       "93      NaN                 <NA>                     <NA>  \n",
       "\n",
       "[94 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[sample_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results of query #1\n",
    "output_df = search_output_dict[sample_key]\n",
    "\n",
    "#results of query #2\n",
    "metadata_df = metadata_dict[sample_key]\n",
    "\n",
    "#result of merging datasets into \"full\" dataframe\n",
    "full_df = df_dict[sample_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>totalDownloads</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kaggle/kaggle-survey-2018</td>\n",
       "      <td>2018 Kaggle Machine Learning &amp; Data Science Su...</td>\n",
       "      <td>4MB</td>\n",
       "      <td>2018-11-03 22:35:07</td>\n",
       "      <td>15381</td>\n",
       "      <td>976</td>\n",
       "      <td>0.85294116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaggle/kaggle-survey-2017</td>\n",
       "      <td>2017 Kaggle Machine Learning &amp; Data Science Su...</td>\n",
       "      <td>4MB</td>\n",
       "      <td>2017-10-27 22:03:03</td>\n",
       "      <td>22997</td>\n",
       "      <td>824</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alopez247/pokemon</td>\n",
       "      <td>Pokémon for Data Mining and Machine Learning</td>\n",
       "      <td>715KB</td>\n",
       "      <td>2017-03-05 15:01:26</td>\n",
       "      <td>10470</td>\n",
       "      <td>241</td>\n",
       "      <td>0.85294116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kashnitsky/mlcourse</td>\n",
       "      <td>mlcourse.ai</td>\n",
       "      <td>51MB</td>\n",
       "      <td>2018-12-09 16:45:09</td>\n",
       "      <td>25404</td>\n",
       "      <td>1376</td>\n",
       "      <td>0.88235295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kaushil268/disease-prediction-using-machine-le...</td>\n",
       "      <td>Disease Prediction Using Machine Learning</td>\n",
       "      <td>30KB</td>\n",
       "      <td>2020-05-15 03:58:44</td>\n",
       "      <td>2413</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0                          kaggle/kaggle-survey-2018   \n",
       "1                          kaggle/kaggle-survey-2017   \n",
       "2                                  alopez247/pokemon   \n",
       "3                                kashnitsky/mlcourse   \n",
       "4  kaushil268/disease-prediction-using-machine-le...   \n",
       "\n",
       "                                               title   size  \\\n",
       "0  2018 Kaggle Machine Learning & Data Science Su...    4MB   \n",
       "1  2017 Kaggle Machine Learning & Data Science Su...    4MB   \n",
       "2       Pokémon for Data Mining and Machine Learning  715KB   \n",
       "3                                        mlcourse.ai   51MB   \n",
       "4         Disease Prediction Using Machine Learning    30KB   \n",
       "\n",
       "           lastUpdated  totalDownloads  totalVotes usabilityRating  \n",
       "0  2018-11-03 22:35:07           15381         976      0.85294116  \n",
       "1  2017-10-27 22:03:03           22997         824       0.8235294  \n",
       "2  2017-03-05 15:01:26           10470         241      0.85294116  \n",
       "3  2018-12-09 16:45:09           25404        1376      0.88235295  \n",
       "4  2020-05-15 03:58:44            2413          42       0.8235294  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collaborators</th>\n",
       "      <th>data</th>\n",
       "      <th>datasetId</th>\n",
       "      <th>datasetSlug</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>id_no</th>\n",
       "      <th>isPrivate</th>\n",
       "      <th>keywords_0</th>\n",
       "      <th>keywords_1</th>\n",
       "      <th>...</th>\n",
       "      <th>totalViews</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>usabilityRating</th>\n",
       "      <th>keywords_6</th>\n",
       "      <th>keywords_7</th>\n",
       "      <th>collaborators_0_role</th>\n",
       "      <th>collaborators_0_username</th>\n",
       "      <th>keywords</th>\n",
       "      <th>collaborators_1_role</th>\n",
       "      <th>collaborators_1_username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>635</td>\n",
       "      <td>pokemon</td>\n",
       "      <td># Context \n",
       "\n",
       "With the rise of the popularity of...</td>\n",
       "      <td>alopez247/pokemon</td>\n",
       "      <td>635</td>\n",
       "      <td>0</td>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>games</td>\n",
       "      <td>...</td>\n",
       "      <td>144794</td>\n",
       "      <td>241</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>32132</td>\n",
       "      <td>mlcourse</td>\n",
       "      <td>![](https://habrastorage.org/webt/ia/m9/zk/iam...</td>\n",
       "      <td>kashnitsky/mlcourse</td>\n",
       "      <td>32132</td>\n",
       "      <td>0</td>\n",
       "      <td>computer science</td>\n",
       "      <td>data visualization</td>\n",
       "      <td>...</td>\n",
       "      <td>200636</td>\n",
       "      <td>1376</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>654897</td>\n",
       "      <td>disease-prediction-using-machine-learning</td>\n",
       "      <td>### Context\n",
       "\n",
       "During the time when Machine Lear...</td>\n",
       "      <td>kaushil268/disease-prediction-using-machine-le...</td>\n",
       "      <td>654897</td>\n",
       "      <td>0</td>\n",
       "      <td>diseases</td>\n",
       "      <td>earth and nature</td>\n",
       "      <td>...</td>\n",
       "      <td>15830</td>\n",
       "      <td>42</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>477512</td>\n",
       "      <td>online-shoppers-intention</td>\n",
       "      <td>**Data Set Information:**\n",
       "\n",
       "The dataset consist...</td>\n",
       "      <td>henrysue/online-shoppers-intention</td>\n",
       "      <td>477512</td>\n",
       "      <td>0</td>\n",
       "      <td>universities and colleges</td>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>17301</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>internet</td>\n",
       "      <td>retail and shopping</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1373456</td>\n",
       "      <td>phishing-dataset-for-machine-learning</td>\n",
       "      <td>### Context\n",
       "\n",
       "Anti-phishing refers to efforts t...</td>\n",
       "      <td>shashwatwork/phishing-dataset-for-machine-lear...</td>\n",
       "      <td>1373456</td>\n",
       "      <td>0</td>\n",
       "      <td>research</td>\n",
       "      <td>exploratory data analysis</td>\n",
       "      <td>...</td>\n",
       "      <td>1465</td>\n",
       "      <td>20</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  collaborators data  datasetId                                datasetSlug  \\\n",
       "0            []   []        635                                    pokemon   \n",
       "1            []   []      32132                                   mlcourse   \n",
       "2            []   []     654897  disease-prediction-using-machine-learning   \n",
       "3            []   []     477512                  online-shoppers-intention   \n",
       "4            []   []    1373456      phishing-dataset-for-machine-learning   \n",
       "\n",
       "                                         description  \\\n",
       "0  # Context \n",
       "\n",
       "With the rise of the popularity of...   \n",
       "1  ![](https://habrastorage.org/webt/ia/m9/zk/iam...   \n",
       "2  ### Context\n",
       "\n",
       "During the time when Machine Lear...   \n",
       "3  **Data Set Information:**\n",
       "\n",
       "The dataset consist...   \n",
       "4  ### Context\n",
       "\n",
       "Anti-phishing refers to efforts t...   \n",
       "\n",
       "                                                  id    id_no  isPrivate  \\\n",
       "0                                  alopez247/pokemon      635          0   \n",
       "1                                kashnitsky/mlcourse    32132          0   \n",
       "2  kaushil268/disease-prediction-using-machine-le...   654897          0   \n",
       "3                 henrysue/online-shoppers-intention   477512          0   \n",
       "4  shashwatwork/phishing-dataset-for-machine-lear...  1373456          0   \n",
       "\n",
       "                  keywords_0                 keywords_1  ... totalViews  \\\n",
       "0     arts and entertainment                      games  ...     144794   \n",
       "1           computer science         data visualization  ...     200636   \n",
       "2                   diseases           earth and nature  ...      15830   \n",
       "3  universities and colleges     arts and entertainment  ...      17301   \n",
       "4                   research  exploratory data analysis  ...       1465   \n",
       "\n",
       "  totalVotes usabilityRating keywords_6           keywords_7  \\\n",
       "0        241        0.852941       <NA>                 <NA>   \n",
       "1       1376        0.882353       <NA>                 <NA>   \n",
       "2         42        0.823529       <NA>                 <NA>   \n",
       "3         33             1.0   internet  retail and shopping   \n",
       "4         20        0.941176       <NA>                 <NA>   \n",
       "\n",
       "  collaborators_0_role collaborators_0_username keywords  \\\n",
       "0                 <NA>                     <NA>      NaN   \n",
       "1                 <NA>                     <NA>      NaN   \n",
       "2                 <NA>                     <NA>      NaN   \n",
       "3                 <NA>                     <NA>      NaN   \n",
       "4                 <NA>                     <NA>      NaN   \n",
       "\n",
       "   collaborators_1_role  collaborators_1_username  \n",
       "0                  <NA>                      <NA>  \n",
       "1                  <NA>                      <NA>  \n",
       "2                  <NA>                      <NA>  \n",
       "3                  <NA>                      <NA>  \n",
       "4                  <NA>                      <NA>  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>totalDownloads</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>usabilityRating</th>\n",
       "      <th>collaborators</th>\n",
       "      <th>data</th>\n",
       "      <th>datasetId</th>\n",
       "      <th>...</th>\n",
       "      <th>ownerUser</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>totalViews</th>\n",
       "      <th>keywords_6</th>\n",
       "      <th>keywords_7</th>\n",
       "      <th>collaborators_0_role</th>\n",
       "      <th>collaborators_0_username</th>\n",
       "      <th>keywords</th>\n",
       "      <th>collaborators_1_role</th>\n",
       "      <th>collaborators_1_username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kaggle/kaggle-survey-2018</td>\n",
       "      <td>2018 Kaggle Machine Learning &amp; Data Science Su...</td>\n",
       "      <td>4MB</td>\n",
       "      <td>2018-11-03 22:35:07</td>\n",
       "      <td>15381</td>\n",
       "      <td>976</td>\n",
       "      <td>0.85294116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaggle/kaggle-survey-2017</td>\n",
       "      <td>2017 Kaggle Machine Learning &amp; Data Science Su...</td>\n",
       "      <td>4MB</td>\n",
       "      <td>2017-10-27 22:03:03</td>\n",
       "      <td>22997</td>\n",
       "      <td>824</td>\n",
       "      <td>0.8235294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alopez247/pokemon</td>\n",
       "      <td>Pokémon for Data Mining and Machine Learning</td>\n",
       "      <td>715KB</td>\n",
       "      <td>2017-03-05 15:01:26</td>\n",
       "      <td>10470</td>\n",
       "      <td>241</td>\n",
       "      <td>0.85294116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kashnitsky/mlcourse</td>\n",
       "      <td>mlcourse.ai</td>\n",
       "      <td>51MB</td>\n",
       "      <td>2018-12-09 16:45:09</td>\n",
       "      <td>25404</td>\n",
       "      <td>1376</td>\n",
       "      <td>0.88235295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kaushil268/disease-prediction-using-machine-le...</td>\n",
       "      <td>Disease Prediction Using Machine Learning</td>\n",
       "      <td>30KB</td>\n",
       "      <td>2020-05-15 03:58:44</td>\n",
       "      <td>2413</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8235294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0                          kaggle/kaggle-survey-2018   \n",
       "1                          kaggle/kaggle-survey-2017   \n",
       "2                                  alopez247/pokemon   \n",
       "3                                kashnitsky/mlcourse   \n",
       "4  kaushil268/disease-prediction-using-machine-le...   \n",
       "\n",
       "                                               title   size  \\\n",
       "0  2018 Kaggle Machine Learning & Data Science Su...    4MB   \n",
       "1  2017 Kaggle Machine Learning & Data Science Su...    4MB   \n",
       "2       Pokémon for Data Mining and Machine Learning  715KB   \n",
       "3                                        mlcourse.ai   51MB   \n",
       "4         Disease Prediction Using Machine Learning    30KB   \n",
       "\n",
       "           lastUpdated  totalDownloads  totalVotes usabilityRating  \\\n",
       "0  2018-11-03 22:35:07           15381         976      0.85294116   \n",
       "1  2017-10-27 22:03:03           22997         824       0.8235294   \n",
       "2  2017-03-05 15:01:26           10470         241      0.85294116   \n",
       "3  2018-12-09 16:45:09           25404        1376      0.88235295   \n",
       "4  2020-05-15 03:58:44            2413          42       0.8235294   \n",
       "\n",
       "  collaborators data  datasetId  ... ownerUser subtitle  totalViews  \\\n",
       "0           NaN  NaN       <NA>  ...      <NA>     <NA>        <NA>   \n",
       "1           NaN  NaN       <NA>  ...      <NA>     <NA>        <NA>   \n",
       "2           NaN  NaN       <NA>  ...      <NA>     <NA>        <NA>   \n",
       "3           NaN  NaN       <NA>  ...      <NA>     <NA>        <NA>   \n",
       "4           NaN  NaN       <NA>  ...      <NA>     <NA>        <NA>   \n",
       "\n",
       "   keywords_6 keywords_7 collaborators_0_role collaborators_0_username  \\\n",
       "0        <NA>       <NA>                 <NA>                     <NA>   \n",
       "1        <NA>       <NA>                 <NA>                     <NA>   \n",
       "2        <NA>       <NA>                 <NA>                     <NA>   \n",
       "3        <NA>       <NA>                 <NA>                     <NA>   \n",
       "4        <NA>       <NA>                 <NA>                     <NA>   \n",
       "\n",
       "  keywords collaborators_1_role collaborators_1_username  \n",
       "0      NaN                 <NA>                     <NA>  \n",
       "1      NaN                 <NA>                     <NA>  \n",
       "2      NaN                 <NA>                     <NA>  \n",
       "3      NaN                 <NA>                     <NA>  \n",
       "4      NaN                 <NA>                     <NA>  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
