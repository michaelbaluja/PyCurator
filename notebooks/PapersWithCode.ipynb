{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e707d5",
   "metadata": {},
   "source": [
    "# Papers With Code API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4519f65",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbaf57",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048294d5",
   "metadata": {},
   "source": [
    "This notebook utilizes the Papers With Code API. Follow these steps in order to get the necessary credentials to continue:\n",
    "1. Create a Papers With Code account at https://paperswithcode.com/accounts/register?next=/\n",
    "2. After logging in, click on the user account icon in the top right corner, and click on 'Get API token'\n",
    "3. Click on 'Generate API Token'\n",
    "4. Load API key:\n",
    "    - For repeated use, follow the ```pickle_tutorial.ipynb``` instructions to create create a ```./credentials.pkl``` file that holds a dictionary containing the entry ```{'PAPERSWITHCODE_TOKEN': MYKEY}```, with MYKEY being your API key.\n",
    "    - For sparser use, users can run the credentials cell and paste their API key when prompted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d3af42",
   "metadata": {},
   "source": [
    "## Additional Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e730f3b",
   "metadata": {},
   "source": [
    "Documentation Guide:\n",
    "- Papers With Code API ([Papers With Code](https://paperswithcode.com/api/v1/docs/))\n",
    "- Papers With Code API ([readthedocs](https://paperswithcode-client.readthedocs.io/en/latest/))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e3913",
   "metadata": {},
   "source": [
    "## Overview of workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1927dd7c",
   "metadata": {},
   "source": [
    "<img src=\"../images/PapersWithCode_workflow.jpg\" width=600 height=600 align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f201620",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e969c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from flatten_json import flatten\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "try:\n",
    "    with open('credentials.pkl', 'rb') as credentials:\n",
    "        PWC_TOKEN = pickle.load(credentials)['PAPERSWITHCODE_TOKEN']\n",
    "except:\n",
    "    PWC_TOKEN = input('Please enter your Papers With Code API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0cd46",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0785e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://paperswithcode.com/api/v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329eb2d",
   "metadata": {},
   "source": [
    "## Query #1: query API based on search types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56fc734",
   "metadata": {},
   "source": [
    "Function `get_all_search_outputs` queries the Papers with Code API for all search types specified and returns the results as a dictionary of dataframes (one dataframe for each query combination)\n",
    "- Calls function `get_individual_search_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ab1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_search_outputs(search_types, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Call the Papers With Code API for each search type. \n",
    "    Results are retured in results['({type},)'] = df\n",
    "    \n",
    "    Params:\n",
    "    - search_types : list-like \n",
    "        collection of search types to query over\n",
    "    - flatten_output : bool, optional (default=False)\n",
    "        flag for flattening nested columns of output\n",
    "    \n",
    "    Returns:\n",
    "    - results : dict\n",
    "        dictionary consisting of returned DataFrames from get_search_output for each query\n",
    "    \"\"\"\n",
    "    \n",
    "    results = OrderedDict()\n",
    "\n",
    "    for search_type in search_types:\n",
    "        results[(search_type,)] = get_individual_search_output(search_type, flatten_output)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76610fe6",
   "metadata": {},
   "source": [
    "Function `_conduct_search_over_pages` is a helper function used to iterate over search result pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conduct_search_over_pages(search_url, search_params, flatten_output=False):\n",
    "    search_df = pd.DataFrame()\n",
    "    \n",
    "    # Conduct a search, extract json results\n",
    "    response = requests.get(url = search_url, params=search_params)\n",
    "    output = response.json()\n",
    "\n",
    "    # Search over all valid pages\n",
    "    while output.get('results') and search_params['page'] < 2:\n",
    "        # Flatten nested json\n",
    "        if flatten_output:\n",
    "            output = [flatten(result) for result in output['results']]\n",
    "        else:\n",
    "            output = output['results']\n",
    "\n",
    "        # Add results to cumulative DataFrame\n",
    "        output_df = pd.DataFrame(output)\n",
    "        output_df['page'] = search_params['page']\n",
    "\n",
    "        search_df = pd.concat([search_df, output_df]).reset_index(drop=True)\n",
    "\n",
    "        # Increment page for search\n",
    "        search_params['page'] += 1\n",
    "        \n",
    "        # Conduct a search\n",
    "        response = requests.get(url = search_url, params=search_params)\n",
    "        \n",
    "        # Ensure we've received results if they exist\n",
    "        # 200: OK, 404: page not found\n",
    "        while response.status_code not in [200, 404]:\n",
    "            print(f'Search error {response.status_code} on page {search_params[\"page\"]}')\n",
    "            search_params['page'] += 1\n",
    "            # Conduct a search, extract json results\n",
    "            response = requests.get(url = search_url, params=search_params)\n",
    "            \n",
    "        # Extract json results\n",
    "        output = response.json()\n",
    "    \n",
    "    return search_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5377bece",
   "metadata": {},
   "source": [
    "Function `get_individual_search_output` queries the Papers with Code API with the specified search type ('conferences', 'datasets', 'evaluations', 'papers', or 'tasks')\n",
    "- Calls function `_conduct_search_over_pages`\n",
    "- Result is a dataframe (one dataframe per search type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_search_output(search_type, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Calls the Papers With Code API with the specified search term and returns the search output results.\n",
    "    \n",
    "    Params:\n",
    "    - search_type : str\n",
    "        Must be in ('conferences', 'datasets', 'evaluations', 'papers', 'tasks')\n",
    "    - flatten_output : bool, optional (default=False)\n",
    "        flag for flattening nested columns of output\n",
    "   \n",
    "    Returns:\n",
    "    - pandas.DataFrame\n",
    "        DataFrame containing the output of the search query\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make sure our input is valid\n",
    "    assert search_type in ('conferences', 'datasets', 'evaluations', 'papers', 'tasks'), \\\n",
    "        f'Invalid search type \"{search_type}\"'\n",
    "    \n",
    "    # Set search variables\n",
    "    start_page = 1\n",
    "    page_size = 500 # Seems to be max size\n",
    "    search_url = f'{BASE_URL}/{search_type}'\n",
    "    \n",
    "    search_params = {\n",
    "        'page': start_page,\n",
    "        'items_per_page': page_size\n",
    "        }\n",
    "    \n",
    "    return _conduct_search_over_pages(search_url, search_params, flatten_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b36dc",
   "metadata": {},
   "source": [
    "#### Run query #1 functions - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_types = ['papers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e53576",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_output_dict = get_all_search_outputs(search_types, flatten_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b98328",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_output_dict[('papers',)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905bfc0",
   "metadata": {},
   "source": [
    "## Query #2: query API for full metadata for hits from initial query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ea2e3",
   "metadata": {},
   "source": [
    "Function `get_query_metadata` extracts metadata associated with each object based on object path and formats as dataframe\n",
    "- Calls function `_conduct_search_over_pages`\n",
    "- Output is single dataframe for each search type (matching each dataframe in result #1 dictionary output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_metadata(object_paths, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Retrieves the metadata for the file/files listed in object_paths\n",
    "    \n",
    "    Params:\n",
    "    - object_paths : str/list-like\n",
    "        string or list of strings containing the paths for the objects\n",
    "    - flatten_output : bool, optional (default=False)\n",
    "        flag for flattening nested columns of output\n",
    "    \n",
    "    Returns:\n",
    "    - metadata_dict : dict\n",
    "        Dictionary of DataFrames containing metadata for the requested datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    # If a singular search term is provided as a string, need to wrap it in a list\n",
    "    if type(object_paths) == str:\n",
    "        object_paths = [object_paths]\n",
    "    \n",
    "    # Make sure our input is valid\n",
    "    assert len(object_paths) > 0, 'Please enter at least one object id'\n",
    "    \n",
    "    metadata_types = ('methods', 'repositories', 'results', 'tasks')\n",
    "    \n",
    "    start_page = 1\n",
    "    metadata_dict = dict()\n",
    "    \n",
    "    # Searches for each of the metadata types that are present for the search type we conducted\n",
    "    for metadata_type in metadata_types:\n",
    "        search_df = pd.DataFrame()\n",
    "        print(f'Querying {metadata_type}')\n",
    "        \n",
    "        # Searches over each object\n",
    "        for object_path in tqdm(object_paths):\n",
    "            search_url = f'{BASE_URL}/papers/{object_path}/{metadata_type}'\n",
    "            search_params = {'page': start_page}\n",
    "\n",
    "            # Conduct the search & add supplementary material to the DataFrame\n",
    "            object_df = _conduct_search_over_pages(search_url, search_params, flatten_output)\n",
    "            object_df['id'] = object_path\n",
    "            object_df['page'] = search_params['page']\n",
    "            \n",
    "            # Merge with the cumulative search DataFrame\n",
    "            search_df = pd.concat([search_df, object_df]).reset_index(drop=True)\n",
    "            \n",
    "        metadata_dict[(metadata_type, )] = search_df\n",
    "\n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965daa2b",
   "metadata": {},
   "source": [
    "Function `get_all_metadata` uses a `for` loop to put dataframes into an ordered dictionary, matching result #1 ordered_dictionary\n",
    "- Calls function `get_query_metadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ccd7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_all_metadata(search_output_dict, flatten_output=False):\n",
    "    \"\"\"\n",
    "    Retrieves all of the metadata that relates to the provided DataFrames\n",
    "    \n",
    "    Params:\n",
    "    - search_output_dict : dict\n",
    "        Dictionary of DataFrames from get_all_search_outputs\n",
    "    - flatten_output : bool, optional (default=False)\n",
    "        flag for flattening nested columns of output  \n",
    "      \n",
    "    Returns:\n",
    "    - metadata_dict : collections.OrderedDict\n",
    "        OrderedDict of DataFrames with metadata for each query\n",
    "        Order matches the order of search_output_dict\n",
    "    \"\"\"\n",
    "    metadata_dict = OrderedDict()\n",
    "    for query, df in search_output_dict.items():\n",
    "        print(f'Retrieving {query} metadata')\n",
    "        # Create object paths\n",
    "        object_paths = df.id.values\n",
    "\n",
    "        metadata_dict[query] = get_query_metadata(object_paths, flatten_output)\n",
    "    \n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d25d5",
   "metadata": {},
   "source": [
    "#### Run query #2 functions - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71447ed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_dict = get_all_metadata(search_output_dict, flatten_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188349e",
   "metadata": {},
   "source": [
    "### Take a look at the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4337e",
   "metadata": {},
   "source": [
    "Since we stored the metadata and DataFrames in our dictionaries via tuple keys, we index the metadata_dict as \n",
    "\n",
    "```metadata_dict[('SEARCH_TYPE',)][('METADATA_TYPE', )]```\n",
    "\n",
    "Note that the tuple keys each have a comma after the sole value in order to preserve the tuple structure and relate in form to the other notebooks used in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97975e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which metadata options we have access to\n",
    "for key, dict_ in metadata_dict.items():\n",
    "    print(f'{key[0]}: {[item[0] for item in dict_.keys()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830f573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_dict[('papers',)][('results',)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
