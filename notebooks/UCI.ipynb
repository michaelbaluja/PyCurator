{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf7e5f9",
   "metadata": {},
   "source": [
    "# UCI Webscraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc9e74e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc022c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cfd39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support.select import By\n",
    "import selenium.webdriver.support.expected_conditions as EC\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from flatten_json import flatten\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b115f",
   "metadata": {},
   "source": [
    "## Variable Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e098c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fe9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _combine_paths(base_path, path_dict):\n",
    "    return {attr: f'{base_path} > {path}' for attr, path in path_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145031b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://archive-beta.ics.uci.edu/ml/datasets'\n",
    "base_path = 'div:nth-child(2) > div > div.MuiGrid-root.MuiGrid-container.MuiGrid-align-items-xs-flex-start.MuiGrid-justify-xs-center'\n",
    "\n",
    "wait_path = 'div:nth-child(2) > div > div.MuiGrid-root.MuiGrid-container.MuiGrid-align-items-xs-flex-start.MuiGrid-justify-xs-center > div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 > div:nth-child(4) > div.MuiCollapse-container.MuiCollapse-entered > div > div > div > div > table > tbody > tr:nth-child(1) > td:nth-child(2) > p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d889f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_attribute_paths = {\n",
    "    'creators': 'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div:nth-child(3) '\n",
    "                '> div.MuiCollapse-container.MuiCollapse-entered '\n",
    "                '> div '\n",
    "                '> div '\n",
    "                '> div '\n",
    "                '> div '\n",
    "                '> ul '\n",
    "                '> li '\n",
    "                '> div '\n",
    "                '> span '\n",
    "                '> h6',\n",
    "    'keywords': 'div.MuiGrid-root.MuiGrid-grid-xs-12.MuiGrid-grid-md-3 '\n",
    "                '> div:nth-child(1) '\n",
    "                '> div.MuiCardContent-root '\n",
    "                '> div '\n",
    "                '> span.MuiChip-label'\n",
    "}\n",
    "\n",
    "single_attribute_paths = {\n",
    "    'abstract': 'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div:nth-child(2) '\n",
    "                '> div.MuiCardContent-root.MuiGrid-root.MuiGrid-container.MuiGrid-justify-xs-space-between '\n",
    "                '> div.MuiGrid-root.MuiGrid-container.MuiGrid-direction-xs-column '\n",
    "                '> div '\n",
    "                '> p',\n",
    "    'associated_tasks': 'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div:nth-child(2) '\n",
    "                '> div.MuiCardContent-root.MuiGrid-root.MuiGrid-container.MuiGrid-justify-xs-space-between '\n",
    "                '> div.MuiGrid-root.MuiGrid-container.MuiGrid-spacing-xs-3 '\n",
    "                '> div:nth-child(4) '\n",
    "                '> p',\n",
    "    'dataset': 'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div.MuiPaper-root.MuiCard-root.jss15.MuiPaper-elevation3.MuiPaper-rounded '\n",
    "                '> div.MuiCardHeader-root '\n",
    "                '> div.MuiCardHeader-content '\n",
    "                '> h5',\n",
    "    'dataset_characteristics': 'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div:nth-child(2) '\n",
    "                '> div.MuiCardContent-root.MuiGrid-root.MuiGrid-container.MuiGrid-justify-xs-space-between '\n",
    "                '> div.MuiGrid-root.MuiGrid-container.MuiGrid-spacing-xs-3 '\n",
    "                '> div:nth-child(2) '\n",
    "                '> p',\n",
    "    'doi': 'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div:nth-child(2) '\n",
    "                '> div.MuiCardContent-root.MuiGrid-root.MuiGrid-container.MuiGrid-justify-xs-space-between '\n",
    "                '> div.MuiGrid-root.MuiGrid-container.MuiGrid-spacing-xs-3 '\n",
    "                '> div:nth-child(5) '\n",
    "                '> p',\n",
    "    'donation_date': 'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div.MuiPaper-root.MuiCard-root.jss15.MuiPaper-elevation3.MuiPaper-rounded '\n",
    "                '> div.MuiCardHeader-root '\n",
    "                '> div.MuiCardHeader-content '\n",
    "                '> span '\n",
    "                '> p',\n",
    "    'license': 'div.MuiGrid-root.MuiGrid-grid-xs-12.MuiGrid-grid-md-3 '\n",
    "                '> div:nth-child(2) '\n",
    "                '> div.MuiCardContent-root '\n",
    "                '> p:nth-child(1) '\n",
    "                '> a.MuiTypography-root.MuiLink-root.MuiLink-underlineHover.MuiTypography-colorInherit',\n",
    "    'num_citations': 'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div.MuiPaper-root.MuiCard-root.jss15.MuiPaper-elevation3.MuiPaper-rounded '\n",
    "                '> div.MuiCardContent-root.MuiGrid-root.MuiGrid-container.MuiGrid-align-items-xs-center.MuiGrid-justify-xs-space-between '\n",
    "                '> div:nth-child(1) '\n",
    "                '> div:nth-child(2) '\n",
    "                '> p',\n",
    "    'num_instances': 'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div:nth-child(2) '\n",
    "                '> div.MuiCardContent-root.MuiGrid-root.MuiGrid-container.MuiGrid-justify-xs-space-between '\n",
    "                '> div.MuiGrid-root.MuiGrid-container.MuiGrid-spacing-xs-3 '\n",
    "                '> div:nth-child(6) '\n",
    "                '> p',\n",
    "    'num_views':'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div.MuiPaper-root.MuiCard-root.jss15.MuiPaper-elevation3.MuiPaper-rounded '\n",
    "                '> div.MuiCardContent-root.MuiGrid-root.MuiGrid-container.MuiGrid-align-items-xs-center.MuiGrid-justify-xs-space-between '\n",
    "                '> div:nth-child(1) '\n",
    "                '> div:nth-child(1) '\n",
    "                '> p',\n",
    "    'subject_area': 'div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 '\n",
    "                '> div:nth-child(2) '\n",
    "                '> div.MuiCardContent-root.MuiGrid-root.MuiGrid-container.MuiGrid-justify-xs-space-between '\n",
    "                '> div.MuiGrid-root.MuiGrid-container.MuiGrid-spacing-xs-3 '\n",
    "                '> div:nth-child(3) '\n",
    "                '> p'\n",
    "}\n",
    "\n",
    "single_attribute_paths = _combine_paths(base_path, single_attribute_paths)\n",
    "variable_attribute_paths = _combine_paths(base_path, variable_attribute_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_base_path = 'div:nth-child(2) > div > div.MuiGrid-root.MuiGrid-container.MuiGrid-align-items-xs-flex-start.MuiGrid-justify-xs-center > div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 > div:nth-child(5) > div.MuiCollapse-container.MuiCollapse-entered > div > div > div > div > table > tbody'\n",
    "descriptive_question_base_path = 'div:nth-child(2) > div > div.MuiGrid-root.MuiGrid-container.MuiGrid-align-items-xs-flex-start.MuiGrid-justify-xs-center > div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-9 > div:nth-child(4) > div.MuiCollapse-container.MuiCollapse-entered > div > div > div > div > table > tbody'\n",
    "tabular_attribute_paths = {\n",
    "    'missing_values': 'tr:nth-child(1) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p',\n",
    "    'missing_value_placeholder': 'tr:nth-child(2) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p',\n",
    "    'num_attributes': 'tr:nth-child(3) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p'\n",
    "}\n",
    "\n",
    "descriptive_question_attribute_paths = {\n",
    "    'creation_purpose': 'tr:nth-child(1) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p',\n",
    "    'funders': 'tr:nth-child(2) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p',\n",
    "    'instances_represent': 'tr:nth-child(3) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p',\n",
    "    'recommended_data_split': 'tr:nth-child(4) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p',\n",
    "    'sensitive_data': 'tr:nth-child(5) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p',\n",
    "    'preprocessing_done': 'tr:nth-child(6) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p',\n",
    "    'previous_tasks': 'tr:nth-child(7) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p',\n",
    "    'additional_info': 'tr:nth-child(8) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p',\n",
    "    'citation_requests/acknowledgements': 'tr:nth-child(9) '\n",
    "                '> td:nth-child(2) '\n",
    "                '> p'\n",
    "}\n",
    "\n",
    "tabular_attribute_paths = _combine_paths(tabular_base_path, tabular_attribute_paths)\n",
    "descriptive_question_attribute_paths = _combine_paths(descriptive_question_base_path, descriptive_question_attribute_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_attribute_paths = {**single_attribute_paths, **descriptive_question_attribute_paths}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9af07",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_results(results):\n",
    "    \"\"\"Cleans the results scraped from the dataset page.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results : dict\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove unnecessary text from temporal/numeric cells\n",
    "    if 'Donated on' in results.get('donation_date'):\n",
    "        results['donation_date'] = results['donation_date'].replace('Donated on', '').strip()\n",
    "    if 'citations' in results.get('num_citations'):\n",
    "        results['num_citations'] = int(results['num_citations'].replace('citations', '').strip())\n",
    "    if 'views' in results.get('num_views'):\n",
    "        results['num_views'] = int(results['num_views'].replace('views', '').strip())\n",
    "    \n",
    "    return results\n",
    "\n",
    "def is_tabular(soup):\n",
    "    \"\"\"For a soup object relating to a dataset page, returns if the dataset is tabular.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    soup : BeautifulSoup\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "    \"\"\"\n",
    "            \n",
    "    return 'Tabular Data Properties' in soup.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ebccae",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d192b",
   "metadata": {},
   "source": [
    "## Gather Dataset ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_ids(dataset_list_url, instance_path, driver):\n",
    "    \"\"\"Returns the dataset ids for all datasets on the given page.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_list_url : str\n",
    "        Web url for page containing links to the datasets to scrape.\n",
    "    instance_path : str\n",
    "        CSS Selector path for the datasets on the page.\n",
    "    driver : WebDriver\n",
    "        Selenium webdriver to use for html extraction.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataset_ids : list\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the requested url\n",
    "    driver.get(dataset_list_url)\n",
    "    \n",
    "    # Wait for instances to load on page\n",
    "    WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, instance_path)))\n",
    "    \n",
    "    # Create parsable html object\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    # Gather the instances and parse the ids\n",
    "    dataset_ids = [instance.attrs['href'].split('/')[-1] for instance in soup.select(instance_path)]\n",
    "    \n",
    "    return dataset_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1396ca89",
   "metadata": {},
   "source": [
    "## Scraping Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_attribute_value(soup, attribute):\n",
    "    \"\"\"Retrieves the requested value from the soup object.\n",
    "    \n",
    "    For a page attribute with a single value ('abstract', 'num_instances', etc), \n",
    "    returns the value. For attributes with potentially multiple values, such as \n",
    "    'keywords', use get_variable_attribute_values(...).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    soup : BeautifulSoup\n",
    "        BeautifulSoup object containing the html to be parsed.\n",
    "    attribute : str\n",
    "        Name of the attribute to extract from the soup.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Value of attribute.\n",
    "    \"\"\"\n",
    "    \n",
    "    path = single_attribute_paths[attribute]\n",
    "\n",
    "    return soup.select_one(path).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_attribute_values(soup, attribute):\n",
    "    \"\"\"Retrieves the requested value from the soup object.\n",
    "    \n",
    "    For a page attribute with potentially multiple values, such as 'keywords', \n",
    "    return the values as a list. For attributes with a single value, such as \n",
    "    'abstract', use get_single_attribute_value(...).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    soup : BeautifulSoup\n",
    "        BeautifulSoup object containing the html to be parsed.\n",
    "    attribute : str\n",
    "        Name of the attribute to extract from the soup.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Value(s) of attribute.\n",
    "    \"\"\" \n",
    "    \n",
    "    path = variable_attribute_paths[attribute]\n",
    "    \n",
    "    return [tag.text for tag in soup.select(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baabac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_page_data(url, \n",
    "                             driver, \n",
    "                             single_attribute_paths=None, \n",
    "                             variable_attribute_paths=None, \n",
    "                             clean=True,\n",
    "                             flatten_output=False,\n",
    "                             **kwargs):\n",
    "    \"\"\"Returns all data from the requested page.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "    driver : WebDriver\n",
    "        Selenium webdriver to use for html extraction.\n",
    "    single_attribute_paths : dict, optional (default=None)\n",
    "        Selector paths to use for data extraction on\n",
    "        single-valued attributes.\n",
    "    variable_attribute_paths : dict, optional (default=None)\n",
    "        Selector paths to use for data extraction on \n",
    "        variable-valued attributes.\n",
    "    clean : boolean, optional (default=True)\n",
    "    flatten_output : boolean, optional (default=False)\n",
    "        Flag for specifying if nested output should be flattened.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result_dict : dict\n",
    "    \"\"\"\n",
    "    \n",
    "    tabular_attribute_paths = kwargs.get('tabular_attribute_paths', None)\n",
    "    \n",
    "    # Get the requested url\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for pertinent sections to load\n",
    "    WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, wait_path)))\n",
    "    \n",
    "    # Extract and convert html data\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    # Add tabular info\n",
    "    if is_tabular(soup) and tabular_attribute_paths:\n",
    "        try:\n",
    "            single_attribute_paths = {**single_attribute_paths, **tabular_attribute_paths}\n",
    "        except NameError:\n",
    "            single_attribute_paths = tabular_attribute_paths\n",
    "    \n",
    "    # Retrieve attribute values from parsed html\n",
    "    if single_attribute_paths:\n",
    "        single_values = {attribute: get_single_attribute_value(soup, attribute) \n",
    "                         for attribute in single_attribute_paths}\n",
    "    else:\n",
    "        single_values = None\n",
    "    if variable_attribute_paths:\n",
    "        variable_values = {attribute: get_variable_attribute_values(soup, attribute)\n",
    "                           for attribute in variable_attribute_paths}\n",
    "    else:\n",
    "        single_values = None\n",
    "    \n",
    "    result_dict = {**single_values or dict(), **variable_values or dict()}\n",
    "    \n",
    "    # Clean results (if instructed)\n",
    "    if clean:\n",
    "        result_dict = clean_results(result_dict)\n",
    "    \n",
    "    # Flatten output (if instructed)\n",
    "    if flatten_output:\n",
    "        result_dict = flatten(result_dict)\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_page_data(base_url, \n",
    "                      driver,\n",
    "                      page_ids,\n",
    "                      single_attribute_paths=None, \n",
    "                      variable_attribute_paths=None, \n",
    "                      clean=True,\n",
    "                      flatten_output=False):\n",
    "    \"\"\"Returns data for all pages for the requested base url.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_url : str\n",
    "    driver : WebDriver\n",
    "        Selenium webdriver to use for html extraction.\n",
    "    page_ids : list-like\n",
    "        dataset ids to use for pulling up each page.\n",
    "    single_attribute_paths : dict, optional (default=None)\n",
    "        Selector paths to use for data extraction on \n",
    "        single-valued attributes.\n",
    "    variable_attribute_paths : dict, optional (default=None)\n",
    "        Selector paths to use for data extraction on \n",
    "        variable-valued attributes.\n",
    "    clean : boolean, optional (default=True)\n",
    "    flatten_output : boolean, optional (default=False)\n",
    "        Flag for specifying if nested output should be flattened.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataset_df : DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create hollow output dataframe\n",
    "    dataset_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop for each dataset page\n",
    "    for page_id in tqdm(page_ids):\n",
    "        url = f'{base_url}/{page_id}'\n",
    "        \n",
    "        # Retrieve and clean results\n",
    "        results = get_individual_page_data(url=url, \n",
    "                                           driver=driver, \n",
    "                                           single_attribute_paths=single_attribute_paths, \n",
    "                                           variable_attribute_paths=variable_attribute_paths,\n",
    "                                           clean=clean,\n",
    "                                           flatten_output=flatten_output)\n",
    "        # Add results to total result dataframe\n",
    "        dataset_df = dataset_df.append(results, ignore_index=True)\n",
    "    \n",
    "    # Remove unnecessary nested columns\n",
    "    # Datasets that don't have nested data will force the DataFrame to keep the nested column names\n",
    "    if flatten_output:\n",
    "        dataset_df = dataset_df.drop(columns=variable_attribute_paths.keys())\n",
    "    \n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de3230",
   "metadata": {},
   "source": [
    "## Scraping Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids = get_dataset_ids(dataset_list_url='https://archive-beta.ics.uci.edu/ml/datasets?&p%5Boffset%5D=0&p%5Blimit%5D=591&p%5BorderBy%5D=NumHits&p%5Border%5D=desc',\n",
    "                              instance_path='div:nth-child(2) > div > div > div.jss10 > div > div.MuiTableContainer-root > table > tbody > tr > div > li > div > div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-12.MuiGrid-grid-md-11 > div > span > div > div.MuiGrid-root.MuiGrid-item.MuiGrid-grid-xs-8.MuiGrid-grid-sm-10 > p > a',\n",
    "                              driver=driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = get_all_page_data(base_url=base_url, \n",
    "                               driver=driver, \n",
    "                               page_ids=dataset_ids,\n",
    "                               single_attribute_paths=single_attribute_paths, \n",
    "                               variable_attribute_paths=variable_attribute_paths,\n",
    "                               flatten_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a2cf52",
   "metadata": {},
   "source": [
    "### View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ab175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "dataset_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
